{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine-tune Donut on UI RefExp.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BCjMK93Cz3zf",
        "PfTPbvNRCEDF",
        "9t50qDh-lGMg"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3918b2711a8d47d19e5f22abb765531f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_786d00c8fe4c4c6b9c2f34e388224d59",
              "IPY_MODEL_35e229ebf67f4b77ab38b62d4a896576",
              "IPY_MODEL_e385c782a90e45529a6f59eb06a76a1d"
            ],
            "layout": "IPY_MODEL_81fcd4033ad44ee391af69e5777ffc7d"
          }
        },
        "786d00c8fe4c4c6b9c2f34e388224d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f3247368fa46afbb78c0b99b57cf4b",
            "placeholder": "​",
            "style": "IPY_MODEL_da8f115a364449a09578b3ce08e19f68",
            "value": "100%"
          }
        },
        "35e229ebf67f4b77ab38b62d4a896576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41b9e1fc59094361a0596b4a8a6e13a6",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e73b94980f7418faed4495d7bee64c5",
            "value": 3
          }
        },
        "e385c782a90e45529a6f59eb06a76a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd7af999a1a449869384c3b140f28591",
            "placeholder": "​",
            "style": "IPY_MODEL_04b36fb665294766b0eca31b924568b2",
            "value": " 3/3 [00:00&lt;00:00,  3.92it/s]"
          }
        },
        "81fcd4033ad44ee391af69e5777ffc7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f3247368fa46afbb78c0b99b57cf4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da8f115a364449a09578b3ce08e19f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41b9e1fc59094361a0596b4a8a6e13a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e73b94980f7418faed4495d7bee64c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd7af999a1a449869384c3b140f28591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04b36fb665294766b0eca31b924568b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivelin/donut_ui_refexp/blob/main/Fine_tune_Donut_on_UI_RefExp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNMqJ821yNVo"
      },
      "source": [
        "# Fine-tune Donut 🍩 on UI RefExp\n",
        "\n",
        "> _NOTE_: This notebook is based on the [Donut fine-tuning notebooks by Niels Rogge](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Donut). \n",
        "\n",
        "In this notebook, we'll fine-tune Donut (which is an instance of [`VisionEncoderDecoderModel`](https://huggingface.co/docs/transformers/model_doc/vision-encoder-decoder)) on a [UI RefExp dataset](https://huggingface.co/datasets/ivelin/ui_refexp_saved), which is a dataset consisting of (UI screenshot, prompt, and target bounding box) triplets. This way, the model will learn to look at a screenshot image, and answer a prompt referring to a UI component. For example: \"select the search icon next to the menu drawer\". This could be useful for tasks such as converting natural language app documentation to exectuable tests, bug reporting front end test automation and app support chat bots.\n",
        "\n",
        "## Set-up environment\n",
        "\n",
        "First, let's install the relevant libraries:\n",
        "* 🤗 Transformers, for the model\n",
        "* 🤗 Datasets, for loading + processing the data\n",
        "* PyTorch Lightning, for training the model\n",
        "* Weights and Biases, for logging metrics during training\n",
        "* Sentencepiece, used for tokenization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot1nP9YHz8co",
        "outputId": "63f65524-424d-47f2-bb95-e5db53a91c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OqcGNPJHyOlt"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zMZ6tiMB1JxD"
      },
      "outputs": [],
      "source": [
        "!pip install -q pytorch-lightning wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdgBa6qK3nup",
        "outputId": "f0817e9d-f9ab-440f-e827-9b88c990912a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens .\n",
            "    \n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid.\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWoh-cGbnWpM",
        "outputId": "dae1639d-7ebd-4315-a6cb-abe4683d0b46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mivelin-eth\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWYic8VNyDNU"
      },
      "source": [
        "## Load dataset\n",
        "\n",
        "Next, let's load the dataset from the [hub](https://huggingface.co/datasets/naver-clova-ix/cord-v2). We're prepared a minimal dataset for DocVQA, the notebook for that can be found [here](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/Donut/DocVQA/Creating_a_toy_DocVQA_dataset_for_Donut.ipynb).\n",
        "\n",
        "Important here is that we've added a \"ground_truth\" column, containing the ground truth JSON which the model will learn to generate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5hU27XC2yEot"
      },
      "outputs": [],
      "source": [
        "REFEXP_DATASET_NAME = \"ivelin/ui_refexp_saved\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(REFEXP_DATASET_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "3918b2711a8d47d19e5f22abb765531f",
            "786d00c8fe4c4c6b9c2f34e388224d59",
            "35e229ebf67f4b77ab38b62d4a896576",
            "e385c782a90e45529a6f59eb06a76a1d",
            "81fcd4033ad44ee391af69e5777ffc7d",
            "69f3247368fa46afbb78c0b99b57cf4b",
            "da8f115a364449a09578b3ce08e19f68",
            "41b9e1fc59094361a0596b4a8a6e13a6",
            "5e73b94980f7418faed4495d7bee64c5",
            "cd7af999a1a449869384c3b140f28591",
            "04b36fb665294766b0eca31b924568b2"
          ]
        },
        "id": "hSguzMVA-KCj",
        "outputId": "a1e65aa5-f957-4d9d-e858-6737681643e1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration ivelin--ui_refexp_saved-e577b0c06a93cce7\n",
            "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/ivelin___parquet/ivelin--ui_refexp_saved-e577b0c06a93cce7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3918b2711a8d47d19e5f22abb765531f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be seen, the dataset contains a training, a validation and a test split. And each example consists of an image, a prompt, and a target bounding box."
      ],
      "metadata": {
        "id": "wjI5uyk48V-g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DYk7tDBy-ys",
        "outputId": "c3d23bf8-d371-4f1b-8c16-d9aae72cbf93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetInfo(description='', citation='', homepage='', license='', features={'image': Image(decode=True, id=None), 'image_id': Value(dtype='string', id=None), 'image_file_path': Value(dtype='string', id=None), 'prompt': Value(dtype='string', id=None), 'target_bounding_box': Value(dtype='string', id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name=None, config_name=None, version=None, splits={'train': SplitInfo(name='train', num_bytes=1911005765, num_examples=15624, shard_lengths=[7812, 7812], dataset_name='parquet'), 'validation': SplitInfo(name='validation', num_bytes=60409431, num_examples=471, shard_lengths=None, dataset_name='parquet'), 'test': SplitInfo(name='test', num_bytes=69086257, num_examples=565, shard_lengths=None, dataset_name='parquet')}, download_checksums={'https://huggingface.co/datasets/ivelin/ui_refexp_saved/resolve/38a258997cb5e6dd9b973534d3f860e76a6936a5/data/train-00000-of-00004-2435fd5b921f3ab6.parquet': {'num_bytes': 115897898, 'checksum': 'f873b031b135c2cfbd382b5b0d829765fa6ab754663916596e5247e640cf3cd3'}, 'https://huggingface.co/datasets/ivelin/ui_refexp_saved/resolve/38a258997cb5e6dd9b973534d3f860e76a6936a5/data/train-00001-of-00004-250670235246aad6.parquet': {'num_bytes': 373619154, 'checksum': '999c2ef3f36166fc6cc4717891cf073344674d801f39eaea80bc671458a28eab'}, 'https://huggingface.co/datasets/ivelin/ui_refexp_saved/resolve/38a258997cb5e6dd9b973534d3f860e76a6936a5/data/train-00002-of-00004-043d6d41cfe99613.parquet': {'num_bytes': 346442020, 'checksum': '8cca2f0f53d8b8b9b0b95c2ca27bcb16218bf9d1714c628d0c05c19b283c227a'}, 'https://huggingface.co/datasets/ivelin/ui_refexp_saved/resolve/38a258997cb5e6dd9b973534d3f860e76a6936a5/data/train-00003-of-00004-4f278592e33cf552.parquet': {'num_bytes': 301305092, 'checksum': 'f32e7faf0c47333ed6f340bb335cbbe98ba2be93855cbd2fa5ae7a80784fc5c9'}, 'https://huggingface.co/datasets/ivelin/ui_refexp_saved/resolve/38a258997cb5e6dd9b973534d3f860e76a6936a5/data/validation-00000-of-00001-08fa3b28509964a2.parquet': {'num_bytes': 50875687, 'checksum': 'feab6e0fa1caa9fbc82eaec1980bf915e410b1983e093b03b785a6c06f0ff40e'}, 'https://huggingface.co/datasets/ivelin/ui_refexp_saved/resolve/38a258997cb5e6dd9b973534d3f860e76a6936a5/data/test-00000-of-00001-a2fe3076871b576d.parquet': {'num_bytes': 58401365, 'checksum': 'bc4895cef4cccba734bcef9604c1e72578625ba36eed36e6cc43f984383e4931'}}, download_size=1246541216, post_processing_size=None, dataset_size=2040501453, size_in_bytes=3287042669)\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['image', 'image_id', 'image_file_path', 'prompt', 'target_bounding_box'],\n",
            "        num_rows: 15624\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['image', 'image_id', 'image_file_path', 'prompt', 'target_bounding_box'],\n",
            "        num_rows: 471\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['image', 'image_id', 'image_file_path', 'prompt', 'target_bounding_box'],\n",
            "        num_rows: 565\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(dataset['train'].info)\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Let's look at a sample in the dataset\n",
        "import math\n",
        "import json\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "# change this index from 0 to split size to see different samples\n",
        "sample = dataset['train'][49]\n",
        "image = sample['image']\n",
        "width, height = image.size\n",
        "print(f\"image width, height: {width, height}\")\n",
        "print(f\"prompt: {sample['prompt']}\")\n",
        "\n",
        "bb = json.loads(sample[\"target_bounding_box\"])\n",
        "\n",
        "print(f\"target bounding box: {bb}\")\n",
        "\n",
        "xmin = math.floor(width*bb[\"xmin\"])\n",
        "ymin = math.floor(height*bb[\"ymin\"])\n",
        "xmax = math.floor(width*bb[\"xmax\"])\n",
        "ymax = math.floor(height*bb[\"ymax\"])\n",
        "\n",
        "print(f\"to image pixel values: xmin, ymin, xmax, ymax: {xmin, ymin, xmax, ymax}\")\n",
        "\n",
        "shape = [(xmin, ymin), (xmax, ymax)]\n",
        "\n",
        "# create rectangle image\n",
        "img1 = ImageDraw.Draw(image)  \n",
        "img1.rectangle(shape, outline =\"green\", width=5)\n",
        "image.resize((int(width*0.5), int(height*0.5)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "6f2fjxGaHWli",
        "outputId": "103346bd-aff5-4242-fb26-f128405ecaa9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image width, height: (540, 960)\n",
            "prompt: go to next\n",
            "target bounding box: {'xmin': 0.8759258985519409, 'ymin': 0.03854166716337204, 'xmax': 1.0, 'ymax': 0.1041666641831398}\n",
            "to image pixel values: xmin, ymin, xmax, ymax: (472, 37, 540, 99)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=270x480 at 0x7F7548951F40>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAAHgCAIAAADbnRQAAACTAElEQVR4nOydd5xVxd3/Z+a02+/du5VdFlgWlqUsCIgCUqxYY4stthQLiRprHo2a8jyaoia2GHv0+amJMTEajYIiIEjvdVnYhWXZ3m8vp878/viy57kuxbtIBOO8Xwnu3j13zpw585n5zndmvoMnT56MDoYgCJZlUUpFUbQsCz7EGCOEGGOEEEoppVQQBPjVsiz7X4wxxphSCtcDjDFIgVJKCGGMYYwZY/B1uAD+BN+CKyED8DNcAHmDH+CvmbeA78JfMzMM+TQMQ5Ik+3qMsf0gkHnIDPwMX8lMnDEmSZKu6/CAmXeERzBNUxAE+yuWZWVmD4oRroTCgbtklhKkkPlJZjHaZWWXJ2PMfkF22QqCYBgGFG9mVqHoIE3TNEVRhFKFO5qmaRd+ltg1AbLBGLMsC0rVvmNmKdmZtH+FEoBPDnprO/N2InZFyiwiQRDgiSzLkiSJUgpVMftn+UIOmZZlWXCzzOeEHNvPYD8kfK6qKkII6hn8nFnVIN/wLShTTdPgc9M0LcsyDCPzVcFrgKpmWZZpmlAWsiybpgn37VebAdCJaZp2dYGf4XX2uxI+RwilUim7XdB1HXLVL/8YY8Mw4Ka6rkP5GIYBZZVZjwG4EuplOp2GSqxpGrRBkP9+9QOUrGmapmm2vEEAdhnaQCNiGIau63Zl1TTNLsnM+me3C6ZpwgNC9YKWAlLr98q+EFC7KIpQT6DK2q+v36vPfEZbLZAlaJ4Oegv7SniWg2YPHgT+Cj/3a6SOCodMzurDbqEBxpiiKFBLQBUYY13XXS7XWWedNW3aNL/fH4/HN27c+Nlnn0WjUTvHIDmojoZhFBQUnH766WPHjvX5fB0dHcuWLduwYYPdfaG+rgCaOkppRUXF7NmzKysrEULNzc2ffvrp9u3b+0nFVq8gCCeeeOIZZ5yRn59vmuaOHTsWL17c1NSkKEq/Vwiidbvdp5122rRp03Jzc+Px+KZNm5YuXRoOhw9swEAbBQUFp5122oknnuh0Otvb21esWLF+/fp0Oq0oCrwzOz8IIcMwRo4cOWfOnLKyMkEQmpubP/nkk507d9p9cuYj67rudDrHjx8/Z86cwsJCxtj27ds/+eSTtrY2EAbKaFbhBXm93unTp5944ol5eXmRSGTLli2fffZZKBRyOByZ5QlfNAyjsLDwzDPPrKqqkmU5FAotX74cMg/pH6o6HgooELsJgLcmy3I/g8I2IqCJ8Xq9CCFN06D5g38PdQtN02whYYwzzRzANE232y1JEmPMbvLQ53uzLw/ONMAy+zhFUc444wxoxW21EEIikcjatWvj8TjqE7qu60OHDr3//vunTJmS+cA7duz43e9+t2XLFvtD6OUZY9OnT7/rrrtGjhyZmZVPP/300Ucf7ezszFQXNNVXXnnljTfemJOTY19MKX311VdfeeUVMIdQX89ummYgEPjRj3506aWXyrJsX9/V1fWHP/xh/vz5ma0XIQQy/8ADD0yePDkz87t37/7tb3+7fv16RVHszEObfcYZZ9x5553Dhg3LzPzSpUt/9atfhUKhfq0jY+yKK6743ve+V1hYmPnhq6+++tJLL2XqCh7K6/XOnTv3sssuy8x8T0/Pk08++eGHH0JtyLRehg4deu+995588smZhl9tbe2vf/3rrVu3ZqoL+p+ZM2feeeedQ4cOzTREP/3000ceeaSrq+sIWmLbchs9evTs2bNN02xtbf3444/75RMUlZeXN2vWrOLi4tGjR3u93tbW1sbGxi1btmzdulVV1cwsob4Wwe/3e71euEU8Ho/FYgd23R6P5+GHHx47dqxpmk8++eTixYuhmtmy72cZ2jYwyuj97I4R9VkQ/Z/Ulopt11JKNU279957r7/+epRRX+3vPProo6+//rrT6YR0c3Jynn766XHjxlFKw+Hwa6+9NnHiRKfTqShKbm7uXXfdVVdXZ3dEhmFMmjTpySefzMnJsSyrvr7+H//4x0UXXdTe3j569Ojm5ua77rorsxXRdf3KK6+8//77oQdbunTptm3bLr/88g0bNpxzzjlvvPHG888/bz8YGM0/+9nPLr30UmhB//rXv0qSNGnSpMbGxpkzZ/785z9ftGiRLMtQQJZl5ebm/v73vz/hhBMsy4pEIq+99tqJJ57odrtFUczPz7/11lv37t0rSRKkr6rqxIkT//jHP/p8PtM06+rqPvjgg3PPPbetra2qqqqpqeknP/kJGFqob+h16aWXPvDAA3C75cuXb9my5corr9ywYcPpp5/+9ttvP/PMM5k2EqX05z//+SWXXAKt71tvvSUIwsknn9zc3Dx9+vSf/exnn3zyid0xWpbl9/v/8Ic/jB8/3rKsaDT66quvTp8+XZIkSZIKCwtvueWWhoYGQRDAmEQIVVVV/eEPfwgEAqZp1tbWfvDBB+effz5kvrm5+cc//jFId0AtMcY4lUqdfvrpv/3tbz0eDzzFO++888gjj0C3Cf/KsnzZZZddddVVgwYN6peCruvr1q37y1/+sm7dOtuYr6ys7Orqsixr4sSJUIkJIa2trXV1dZkaMAzjzDPP/PnPf+7z+eBeuq5v2rTpnnvuSaVSoHz4ellZGaW0qakJZAPvSFEUp9MJ5ZNIJCilw4YNI4Ts27cPhrWZwyox85ltw3rWrFmXXnqpbVKDuY8QAqs0GAxCDwhPdemll44bNw7Go+3t7a+++uqkSZOGDRuWk5Nz1113XXfddQ8//LDdxjidzptuuiknJwf63CVLlrzwwgvQFF1xxRVnnHHGueee+84778DomTFWUlLy3e9+FwSMEPrwww8//vhjURTXrl07derUa6+9dsmSJTt37oQn1zTt1FNPveiiiyBviUTi9ddftyzrkksu2bVr1+mnnz537tx169alUil4KMuyLr/8ctAJxri5uflPf/rT9u3bBw8eHAwG77rrruuvv/5//ud/7HrvcDhuuOEGn88HpvCyZctefPHFVCrV2trqcDhOPfXUOXPmvPPOO9AhUEqLioq+//3voz6De/78+fPmzYPMn3TSSVdcccXChQtramrgjeq6PmPGjPPPP99uQV999VVBELq6uhoaGk499dQbb7xx/fr1iUTCbhcuu+yy8ePH67ouSVJjY+Mrr7xSXV09dOjQ3Nzc22+//Tvf+c5vf/tbqFIwMrnhhhv8fj9kfvny5S+//LKu6+3t7bIsn3baaZdddtlrr73mdDqz1wlCyDTN3NzcW2+91ePxLFy4sKGh4aqrrrrgggvee++9bdu22e9lzJgxt9xyi91FQ5HCeAwhNGPGjEAgsHHjRtAqIaSrq2vkyJH79u3r6OgoKSmBanlQDcuynJOTU1NT8+GHH4IBEggEbEcO1JwHH3ywqqoqGo3GYrEHHnjANE1N05xO5z333DNt2rRQKJRIJO65554777xz7NixmqaFw+EHH3zQNliAz/Vl8GD5+fk//OEPPR4PmMIw9ISWFRRCKQVLgFLq8XjOPPNM1NdnLV68ePz48TfeeKMoiul02jCM6dOn5+bmQqugaVpZWdn48eNRn427efPm66+/fvbs2aIoglF3xhlnOBwOwzBgSHPyySeXlJTAfVtaWvbu3Xv33XeXlJR4PJ6enh6n0zljxgxd12VZJoTAK7dHONXV1Rjjn/3sZ5IkybIcjUbLy8snTpwIvRZYO6eeeipCCJreVatWTZo06brrrnO73YlEAu6el5cHQoIm58QTT4R6b5rm9u3bv/Od75x11lmSJPX29jLGzj77bKfTaTd4J5100uDBg8Fv1tnZuXPnzvvuu6+kpMTn83V1dbnd7tmzZxuGgfp8GGeccQY8CGReFMWf/vSnDodDFMXe3t7hw4dXVVXB9ZRSl8t16qmn2sOAFStWTJw48YYbbpAkKRqNGoZx6qmn5ubmQl20LKusrGzy5MnQohmGsW3btm9/+9unnXYaISQcDluWNWvWLJfLNaCBCiAIQklJSTQa/eUvf/nYY4/V1NQ4nc6xY8fa9ogkSRs3bnzttdf6JQ4XiKIYjUYfffRRcDbANZClkSNHdnd3t7S0HGbcD9evWrXq2WefbWtry8/PV1UVehj4lsPh6Onpue222+67777x48cXFxeffPLJZ5xxhqIoVVVVzz///B133HHPPfc4nc5x48bdf//999133+jRowsKCvr5mT53e2i5f/CDH4wfP55Sunv37vvuu6+np+eBBx5Yvnz5vHnznnzySftKUL8kSS6XC3q06urqt9566/zzz581a9acOXM2b94cDofdbjeYapD1yspKr9cLJfjhhx9u2bLlmmuumT179oknnjhv3jzDMCorKx0Oh20GFBYWwo0IIf/7v/9LKf3Od75zySWX+Hy+5cuXI4RycnIkSQKnh8PhqKqqglFdMpl89tlnTz755DPPPPOqq65qbm7euHGjIAjDhw8HkWOMoUECHdbU1Pz5z38+77zzTj/99NNPP3379u1Qm6HJAGGPGTMGnoUQMm/evI0bN1533XUzZsw48cQTP/zww1QqNWzYMIfDYdvHBQUFUJMwxn/6058YY5dffvlFF13k8XhWrlyJEHK5XFCVGWNut7uyshIST6VSzz777NSpU+fMmXPZZZc1NTVt2LBBluXy8nJ73OhwOIqKiiiliqJs3779r3/967e+9a2ZM2eec845W7duDYfDDocD3Azg6KuoqPB4PJC3jz76aMOGDddff/3MmTMnTZo0b948XdeHDRvm8/kGJBVQqWVZ8Xjc7XbfeuutN99884gRI3Rdb2lpQX3GD0JIUZQXX3xx8eLF9neh/KFB/OUvf7lx40bbG2YbOJIkjRo1qqenB0awB80bjMF27tyZn58/btw46KWhrQTLStO05557bvTo0XPnzt2xY0dzc3MgEMjLy8MYu93uc84559lnn50yZUo4HL7pppvq6urGjRuXTqdjsZjtTIcbiQfetampCX71+Xzjxo1DCFVUVPh8PkmSbIdv5ogN3B2rVq168sknJUmaOXMmY2zixInPPvtsMBgEjwTrc8Drug5F/Pbbbz/33HMjRowYOnQoY+yyyy678MILCSGJRMK27hBC4HSOxWKvvPLKP//5z+uuuw7q7k9+8hOwc8DrYk+zgHHV0NDw1FNP7dy587rrrqOU+ny+F154Abwu0HTZ6UPGVq5c+dRTT2GMZ8yYYVnWhAkT/vCHP9iZhycFtYDZ9s477zz77LPl5eUgvKuuuuqiiy5yuVzRaLSfRwsy/6c//emf//zn1Vdf7XK5KKX3338/JNtvTA82xt69e//whz/U1taC8ZaXlweZ7+eOY33zJCtWrPjjH/8oiuL06dMZY1VVVX/84x/9fj/4l+wpC8g8IeTtt99+9tlnKysrR4wYYZrmlVdeeckllzidzt7eXnDfDwhRFMPh8LJly6666qprrrkG6vqePXu2bdsGL8geADPGfvOb33g8nqlTp0JmwFT505/+tGjRIqfTmemesfsQWZYrKip2796NMQbl274N+w0ihC688MJQKPT666+PGzfO7oLAyIdRq8vlys/PB9Nj4cKFUHRPPvlkc3PzyJEjf/rTn27atKm7u3v8+PG33377008/HQqFYLgBNgXK7FVso/a9995bsWIFIaS4uPimm24KBoM33njjCSecMG3atAsvvBAuhqELSLajo8MwjN/+9rc7duyAEoFSgJxFIhHbayEIwrZt22KxWG1t7SOPPNLZ2Yn6Oii32w3WQm1tbSqVsrPY1taGEFq0aNFLL70EtiNow+fzud1uy7La29vt4WMqldq8eTPG+JVXXvnoo4/gYmjYcnNzZVlWVXXXrl1QlBhjVVWbmpo0TQNPHQzjoKvMz88XBCEcDsfjcfBOQubj8fju3bufeOKJ7u5uhBC8cqfTGQwGMcbbt2+3xxKEEGh05s+fD5462/Hi9/vBm9fZ2Wm7XFKp1MaNGxFCL7300oIFC8C1CO8lPz/f4XBomrZlyxa7tUqn042NjaqqPv7441u2bIEnhR61qKhIkqSenh5wK0H9qK6uTiQSNTU1jz32WGdnJ/h2CSFutzsYDCKEampq0un0QMf0MOX3xhtv9Pb2gkPIsqw///nP0Wi0n7ORENLT0/PYY491dHTgvunRefPmvfHGG5m+L7sJsH+VJKmioqKrq6u1tRV0gjI8V5D4xIkTVVV96KGHTjrpJHssB3eRZfnb3/72v/71r3vvvXfMmDFwpWmaMKCvqan59NNPNU1jjA0ePPi+++574YUX5s2bl5mZ/XfJfGzIYjqdfvzxx3t7e6EdBdsJLBxo72EgAc+QSqU++OADQRDAKM/Ly3M4HKhvdo8Q8tFHH4XDYRCoIAhtbW2ffPKJ3+/Pzc1FCOXl5UEFRX2zCu+//749qy1J0po1axoaGnJzc30+H3gUoNAFQRBFsbW1dcmSJWCAgZ2zePHidDo9aNAgSZIcDkdBQYHdKgiCsHnz5p07d8JrgB7sk08+IYSUlJRgjH0+n6IouG86mVI6b968np4e28PY1ta2fPnynJycnJwcsK/sMRs0XfPmzbNvJ0nS2rVr6+vri4uLnU6nLMuBQAD1TVhhjJuamj777LNMTzpkfsiQIRhjl8sFziLbp7Jx48a6ujrIPPid5s+fLwhCYWGhKIrBYBAaaXvmdOHCheFw2K6mUPJ5eXmBQIAQUlhYCCUGmbcs66OPPoIbDQh4WPCIwKTHsmXLPvzww0xnN9wCLK7a2tpf/epXhmEoirJ69erf/va3yWTyQDcxaN72fTkcjlGjRtlt34HZ+Oyzz2666aZZs2ZBRwr1AW5KCPnOd77zyCOP3H777alUqq6u7uyzz77gggsQQjfeeOP999//3//93z09PZIk/e53v8vPzx8+fPiDDz44bdo0e9QAtxD7ZRG6uYaGhmeeeebOO++Ehsp24YH1Bg25XaU++eSTKVOmPPTQQ4sWLZo8eTJogBAiiuLq1av/9re/wbegfjPG/vd//3fcuHHPP//89u3bp06dCqqDZv7dd99duXIltOKQmUgk8rvf/e6RRx75wx/+EAqFwECCiphOp1966aWWlhbbmStJ0rZt21544YWbb7552LBhgUAARuEwvdDR0fHkk0/CXBsk4nQ633vvvZNOOukXv/jFrFmzJk6cmJ+fb3syNm7c+O6774IYbJvtmWeeee655/7whz9s27Zt2rRpdkdECPnb3/4GmYfChB71sccee+SRR/74xz+Gw+EzzzzTtqENw3j55ZcbGxvtWiKKYnV19UsvvfSjH/1o2LBhbrd78uTJ9qR+e3v7s88+aztAEUKyLM+bN2/q1KkPPfTQ0qVLJ0yYkJeXBx0sxnjDhg1//etfM01NhNArr7wC/uKdO3eefPLJkiTZs9pvvfXWsmXLDlw98IWwvkUV77777tSpU8eOHfvEE09k1jDUN2Kx1bJ06dJnnnnm2muvfeyxx+LxOPjuM+8Ljpnu7m6Y07NXUYwcOZIxZjdeUC1FURQE4fTTT3e73VCMLpcLqgfcN51O33///d/61rcwxj/96U/b29tHjRqlqmokEnnwwQfPPffcffv2QcVYsWKFKIqSJMGqLrvaQ/bwiSeeeNDnp5Tm5eVBPbZNQ5BHKBTKXOwEDv4bb7zxsssugy4FIZROpxcuXPjHP/6xq6vLrg1Qgul0esSIEXfdddfs2bPt2/X09Lz11ltvvvmmvcLKHjIahjF16tS77rprzJgxcL2u6/v27Xv55ZcXLlxoz7IB0C5edtllc+fOzcvLs3O4YcOGp59+evv27ZBD+1lM04TMX3755bafNB6PL168+JlnngmFQpm1B1rfoUOH3n777aeffrp9066urrfeeusvf/mLruv9VieoqnrKKafcc8899nyrZVn79u174YUXPvnkEygZnLHMCaZifvjDH+bn58P14Cd84oknampq+jlbYZb6lltuAVeBXfLz589/4YUXurq6Mpt2uH7w4MH/9V//NXPmTLsqd3R0/P3vf3/jjTfY51emDBTTNPPy8gYPHrx582bbxD3olYZhuN3u4uLiuro6yCE7YFodFGj3DFA4Ho8HYwwSQn0zm8OGDZszZw606fDFzs7OefPmsb5pR6hFYM1KkgSOBHDqwpogEDAhBAbGkAi4HDKzhCdNmnTQ58F9UxkHuh2gU7OfzfYSgDvS7/cnEokdO3ZUV1dnLsVhfSsRoYI6HI7KykqYYAqHw+vWrWtra2MHLKNCCMEzBAKByZMnV1RUUEpbWlrWrl0bDof7vVfct3BG07RBgwZNnTo1Pz/fMIxdu3Zt27YtkUjYL8a+HoYEGOORI0dOmjTJ5/PBgKe+vl7TNOgP+71FSqksy+PGjRs3bpwkSeFweMOGDY2NjdAUHVjVTNPMyck54YQThg0bJghCS0vLxo0bu7u7HQ6HPamcWUSGYRQVFU2ePHnQoEGGYezevXvjxo0HTmZDbwODpfLy8ilTpng8nlQqtWXLlrq6Ohj+9lsAAiUJntyqqipFUSKRyLp165qamux2+qBvPEvgdduFcCiHFbSYmqb1W2d0IJl/tfMGz0X61uYahgEOdAD8ZrIsH/XlknjixIkH+bSvXUd93Vy/v6IMAxSqiO2wgmISBAFeLbQHqE9gqG8xqe25gpEPQghm9DPvm3l3EBilFN4HJN7PnWc7W6B+Z65rgpGP7SuzIX0LY2GwAbeDtge+mGm+Z+Zf13XbIBYEwV5hnZkZ+4vg+rNH8NCGQa76DQ/s1tEwDLvrhip14IuwZWm3jpB56Antxrhf+iAYe0YPCjPT2DhoRckGWyGHSseuA/DS+72Lw2M/kW3O2YZ0P0WB48sehh3x4/TPwPTp0w/zZ9v6sj+BOmHn2PY+2TMtmRXd7gHhu3BxZv3o12BnLpuzKwe0E/AVu/GzRZXZctjlYle4zLp7YCW2e07Up0kAqpqVsWYeZTQQkBn2+fXtB5oQqM/gxJ93a0Jthsc5MBE7/yhjiTvKcND3e/d2+Wd+Dje127LMXgv1tf32S7THfnYzfMTVC1oQnLHk/MBr7HpyqAsOj10rMsc/B7YgtnPlKCLCKPzADKED6vHhsetKZo3MTCfzgswfMp/W/rVfspl1KLOb6me9HDTD/dI/6DP2S5D1+c37aSDzsgO/e5hi6Xd9Zv/T74sHvf6gJXPgVw4s3sz0D1pWBzYfXwZb219YGkcmEnToGnKoiwd6l8Nw8JWkR3CPzKb6oOkceIFtYh3q6wf+tV8RHOpeh0khm7wdSgMDuu+h7m438wf94kGvH9ADHr4ks0zzyPhCGRzmwbNJvN8P9q8iPcSC6KNmfCF0mP0qHM7xD0bYItauol2UDGDYc2RwqXC+zjBkYau2uJaK/06pMIS4VDj/AQhUoJQKlkAoQUd5MI8QQoZgIC4Vzn8IBJV1lFW2VZp4wGtzDgNmWBf1ZWOWGaLBpcL5D0GggmzIR3nakf1fJ8WlwvnPgWHG8FF1eyFkJ3g0Jcjh/AfDpcLhZAWXCoeTFVlJ5SiuOevHgcs6vnya/RLJnOX99z0I5zih3ys+/Bv/wnUDmYsPvlgqsBCD9e3F67eUyN4aeQTA/lJYFWvfCxI84jrN+kJMwK+wpTlz/z3nP5vMBab2ckH2ecjnA8fBBfaqXwD1LZQegFTsxbajR4+GjWb29y3LCgaDZWVlR7CQ0zRNRVHGjRs3bdq0UaNG2VV58uTJY8eORRkhurMEUsjPzy8rK4OYHZRSr9c7atQoCAyFjvaSJ85xBVRUWPqN+la1o4zWE/etFoctLvAJrJQXRRGCH9hA3yAIgmmZGGGUjbMY7udyue688876+vpnn302nU5DjNri4uKf/vSnvb29jz322IDUYprm0KFDb7311rKyMtDMhg0b/vSnP0UikRtuuKG3t/fhhx/O7FsOXDlrr/nNtK9M0zz//PPPPvvsO++8E4KtjBgx4uc///lf/vKXt956y47Q1e+LnP8YMMak7xQD+xPYX8AYg3ALcIFtaMDWg8ztT6gvRL1hGBa1BGl/Ul8sFahe0Wj0lVdeueeee2655ZZnnnkmnU5DeAtFUf785z8fKvLfoRBF8ZprrhkxYsRTTz21d+/e8ePH33bbbclk8umnn37uuecgtjxCyLIsqN+wIRH1LfOGx3M6naAHu6MUBMHpdEKYHNy3FwWiimVuO3E4HKqq2ts2ss8253gGaiBs/7znnnsaGxvfeOMNl8t14403bt68ORqNfu9734MtZeFweMGCBZdffvlzzz3X0tJyzTXXYIzT6fSkSZPsAyeWLFkyf/58WZIty2KIoeynIAVBWLNmze9+97u77777lltueffdd2+77Ta32/3II4/U19fbceKygTEmy3JhYWFnZ+eaNWtSqVRLSwuErnO5XDNmzIhGo3v37qWUXnjhhXPmzDFNc8uWLcXFxe+99153d/fcuXP37t07bNiw8vLy6urqP//5zz09PbBBFIwudMAeBpDHHXfcEQ6Hi4qKSktLa2tr33zzzZ6eHpTF0nHO1whoMUtLS6dOnbply5aamprhw4c3NDRAfOpHHnkkmUxSSru6us4///xrrrlmwYIF55133sMPP9zU1LR+/fqbbrqps7PzH//4h67rgiAQTDDBsFwyWw8YBJhZt27dE088MX78+EcffdThcDz88MO7d+9WFGWgOz/T6fTatWuHDBnyy1/+8pRTTvH5fK+//vqbb77JGJs8eXJVVZVpmjNmzLj55pvD4fD69esnT548Y8aMvLw8OA3i4osvbmtrq66uPuuss84880wQyUF3/GTuPJk4ceLZZ5/d2dm5ZcuW00477Qc/+IE9tju6qyE4x4TMETzEYr788ss9Hg8E2YJYOYIgKIoCm7dfeeWVoUOH/vjHP37//fe3bNkSi8Xq6+sTiUQsFtu7d29XV1e/Iz2y6lXsDeiCIDQ1NSUSiYKCgm3btnV0dNihiQa0/1MQhH/84x+maZ533nm/+MUvurq65s+f/8EHHyCEwPqCWInhcPiJJ55oaWlpamq677777DBFCxYseOGFF3JzcyEosB1c4lA13uo7MGDTpk0vvPACQsjj8Zx88sm5ubkQ+Y77kf9jsCvhvHnzTjzxxPPPP9/qw+12f/e737Usa8WKFR9++GFra2tTU9OMGTPWrVsHW8RtS570nYFFGSVk/2rlrFpTe7N/fn7+gw8+aJrm888/P3r06DvvvBNizA2onkF7D4ci3H333b/61a/a2tq+//3vQxQzQJKkIUOGNDU1JZNJCBOcOSJXVRUiOYCPInO7duYtbF+h7RyEQOAY47179zocDgjRizN22HO+7kDwBkJIPB5/66235syZU1paalmWoig9PT0PP/zwL3/5y48//hghVFVVVV5eXl9fDxGAaUZoXNwXzORz0cyyzIFlWUVFRffee6/T6fz973//z3/+86mnnpo4ceLtt98O8USysWHsGlxQUHD77bfPnj27q6tr6dKlv/nNb5qammbOnAlBVaANSKfTTqcTVAoTLyTjAErb4WaP4O1RHepzZRiGASlommZfBpFWXC4X6ot3fMSRrzjHFbaxzRhzOByyLG/atGnFihX2cQB+v7+qqmrChAlVVVXBYPCGG25YuXLlE088MXnyZAj3bIdJsa13RhmjA1kuyRjz+/0//vGPvV7vb37zm+bmZofDsWnTpscff3zixIk33nhjZov+hVBKE4nECSeccMMNN0yaNKm4uLi8vNzv94dCIfuBdV2vrq4eOXLkKaec4vf74bwky7IydZLpL0d9OqypqSGEXHzxxQUFBSNGjDj99NN1Xa+trYU0hw8fXlpaWllZOWvWrKamps7OTvL5wy45X2tsO2L9+vUQMfC9995btGhRd3d3T0/P1q1bTzvttLPPPnvWrFkjR45saWn54IMP9u7d+/e//33YsGFgbuzcuXPv3r2ZgX5ssppXEQRBVdW1a9fu2LGjoaEBwkZhjNetW/f73/8eQvFmWdvAvR2LxZ566qm5c+eCOedwODo7O99++22YWYfUPvzwwxEjRtx9993RaBT1zUjCfA4kAj2MPbaB/gGip15wwQUzZswAOb3++ut1dXU+nw8hlJeX99vf/tblcmGMn3766WQyCa4z4WDHr3K+dtjt7Kuvvgr1IR6PP/nkk1A9fv/739tXEkI2bNiAEBJF8V//+pcdXf/tt98mhEBIuv6Jf+tb3/rCHNgRijMDvUGcOFVV7aibX1jbcN/x02AmeTyeysrKQCAQi8V27tyZSCQQQhUVFXBwhWmahYWFZWVlyWRy+PDhN9xww8MPP7xly5aKiopIJNLS0qIoSnl5ua7rjY2N9owkZHLYsGGwhmD37t2tra0IIafT+corr2zcuHHevHmlpaV79uxpaGiwQ33arRHn6wXsUlxctdiQjVEto8a0jNGRDhXMjt934CC2n9Fu9Z3fTfvO9LUHt/+Xfpa7IElfKPhM7yrM/IMcs6xnrC/+FTxGKpVat24d6wtRCelDpHpK6eTJk6+//voFCxa43e4LL7ywra1tz549lmVt374dHBSWZe3YsQNjnBlbFhRbX18PRpd91C1EzkcIbd++fdu2bRCCEcZF2b8YzvGPXcEyhy79JtnQ52feoL5lfvegKQ9gF+RBTawvs7YKFh1kfkL7jgpACO3bt2/Hjh3f/va3ZVmur69/4403otFov69k/myP8hFC0ONlZpJS2tzcHA6H7QOVjjjbnK8FB62ZX/jGD9PoZ2WAfZXYZh7MKrpcLggFbWUcpjxQYwm6GjiI7wgOpuIctxxogJnk6IehGIAB9lVih9AGE0tV1cxhEphMA127BWvGkskk4j0J50g57qQCkL7jmuBXe60k6osvPtDUEBcJ58txnEqlH9w9xTnmfD2kwuF8IYSRQ8b5PlIwwxbd7yPlUuH8R8BQt6+7urSa4qO6nI8hi1gQO5xLhfO1B6La9fh6evw9/5YbUIS4VDj/AcimjBE+uqepHAiXCudrDMNMsqRZNbO+gnuJdmAhDudrCv53nBSRCZyvcu655xqGAUvHuE+WwzkQWE6F29vbIXoD1wmHc1BgBbrodDpR3xQ43zfL4RzI/qX79l5cvhmQwzkMfHzC4WQFj3/F4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxUDXy45UN8yn6r5SmAIIcQwwgwhjBhjiGGGEf63r4/6xnBIqTALYWT3OgwhihBDiDEqIAQvBaGMlc+UIIQYZgyiLCGGEEQbEnnH9VWgI50gnVCPSjSRqpg602LYZQUkQTnWWfsP4XC9CrO7BNzXaiFsCBZDCO1vvf6vxaKIIcQIYgghhiAkMsEIKUjmzdpXgMgQQRRbSMaMIQETQWJIoAgR3rEfHbI0wPD+LgIh2L6cceQPwhgxhGCfJuv7A8OIYYQYwrxT+UoQoJ9nSLJIUpAwFpyWjPiavqPHYaQCppXdc2CGMGKMEqPvTwztt8BAFwRhzBCmCFOEGGIYUYyRgJTjrVn7MhEx/00ceCjsQLPHEEKYMQERJDQlk92xxCl5ChWJyAcrR4lDSmV/b4AZ/J8iTBFjlMpYQwRnjO7Z/v8RghAmSCCIIGYhZCJGEbWQKB9XUoHtBhCrsl8YWBtYZG2aJkSFtWstfLdfcGjUF2fsyDAMA36AgJpwHK59alSWMIQMggiihsCcSFjT0ra+pvXkc6YZMiEIfaOOj8k8sgqOGDEMAw7aVhTFPl4u84IsUz7M+4DOGyOEKWIUugssrmlXOnviiCALMxMLjGCKMMNYtCyGCMMMMSRSXbKMgNM5YnBusXgcCcUOTnn44/hgA48dcRx9/gXYEcEzIywfMf0ipsMRuEfQ41GEEKI6Yk6EI4LSLTuwRTSGFfyNk4odITGVSjU2NkajUQhu73K5SkpKCgoK7GsG9O6+0ABDDDHY9sUwbgtFfra6I2YR1aSWKFlY0JFgEswwJkhniCBGBIZkQ8sVDafRfC4pu2dk3pd58qMOYyyRSMApsAe1cyB2uh1CH7C7ETghAz6EQ79Ae18mS6IomqaZSqUwxnAG7REcJCZQjDElyEImMYmoEQXrmLL/Gz1+Q7DD9nZ3d9fW1kKpgjmQTqe7urrKy8tHjBiBBn4A6GFU9blUTGoRhBKJhCPZdsHE3KtPLhmKet1Wby7qzUHxAIp7ccQvxPwonG+2nlUuXj2rPEi73T2Nh3lT/TJ6+F8P+kmWKWd+omna7bffbp+UeeD1cAqFZVm7du166aWX4NQXaIcwxps3b/7f//3fF198cdmyZagvQuyXoaWl5de//jVj7I9//OOLL74IgfrtTiybJ0IIYYQEE2FGZESQiQjDiMnMxAKl3zClIIQQHARZW1sbj8cRQowxu/MnhDQ2NjY1NaG+w60GkOwhPmcIIYoFHQkUIYnpCtYRQproaJPLd+3rnSlpD0yrKMlxh7DHoF7J8uiCv90qzWW+ueOVWysCO3alNjgqc5yeQ90YAt2jvjNZ4fxH+BP8oKoqnFiE+k541HUdNqLZtcSOoUEphW/BlXaDYZpmZvogg87OzlgsZt8L+hY4/QsS13X9vvvuu/nmm3/xi1/EYjHoZ1RV/dWvfvXiiy8ihBwOx/vvv3///fdHo1G7xGHUkXlmi509O8P98gndV2lpKSEkHA6Hw2HUdxSMaZr24Z1gmMGNIJI/HFcGn6iqihAjommQXGJQ5ERFaSqigpBfdzONfMO2I0GhdXZ2xuNxh8MxfPhwr9drGIYgCGVlZXl5eZTSlpaWdDo9UMs5y0ZxfzeOMfNRtKvDdSNpmltZ/LuxJc9XpzZ296QdhiOpnOrqvOGEYNhfcP8a1t7R63fvbcRDDpUivOw33nhj9erVHo9n7ty5FRUVzzzzTDqdbmxsdLvdP/nJT1wu15NPPul2u6urqysrK2+77TaXy7Vy5co333zTMIyLL774jDPOePnll5ubm9Pp9L333jtv3rzly5eLonj77bd7PJ533nnnhz/8YTqdfv7552+99VaHw/Hyyy+fe+65oihCb7By5co33niDUvq9731v2rRpb775Zn19fU9Pz5133nnttdfOnTv329/+Nus7o/jll1/WNO25554Lh8Pd3d3f+c53Xn755f/93/+988479+3b9+STT1qWNXTo0MGDB5911lnPPvusz+fbsWPHmDFjRo8e/c9//lMUxdtuu62iomLXrl2vvfZaNBodPXr0j3/8Y8MwoPGzj8RAfdJavXr1n//8Z8MwvvWtb51zzjmJROKFF17YvXt3QUHBbbfdVlhY+PLLL6fT6b1794oEXXLhefOXb+tpqvv2Zd+SSk+0LMqIJRKBfPO6FdM0e3t7oflLp9Pl5eVNTU3BYFCSpJaWFlEUU6lUNBqFrfLZMzBhmUyIOH2WHDdT8jNba3dZwlMVju9UyoYkTsjLfXyq88Qg/svqtj29qupwtUt+iRgHTQfORlqwYMGiRYvuuOOOoqKiX//617qu//3vf6+vr7/22mv37t37yCOPpFKpl156ybKsa6+99p133nnttdeampruvvvuU0455cILL/zv//7vmpqaDz74YOPGjbNnz16/fv2//vWvO+64Y/z48Q888ADG+IMPPujt7d26detDDz20Zs2aWCz29ttvwxBFluWmpqb777//vPPOO++88x544IHOzs5ly5Z98MEHp556am5u7sSJEwOBgO0i6+rqWr58+V133bVq1apbbrnloYceeu6556677rqGhoZoNHr//febpnn55ZcvWbJkwYIFIE6Hw3HVVVe9+OKLL7744nXXXccYe+yxxyzLevzxx0tLS++6667333//gw8+iEajb775Zr/ywRg3Nzffcccds2fPPv/88//nf/6nvr7+0UcfXb9+/Q9/+MNwOHzfffeZpvnee+9t3Ljxyiuv7OrquunmH06efMK0adN++tP7O3u6wI1P/t1h5I4/wFQ2DAPqWGtra1dX1/jx4wOBwN69e20fpmEYAx2rDMzUFpjJaCrkyBmWbDu7vNIVtP5nV+jMYWUPjEQBmfxzZ88oH7lsrPdvK3ub8WAZi45DmIPQS55xxhk5OTnr1q2Lx+N79+5VVdXn81199dXTpk174IEHbrvttkgkEgwGr7nmmuLi4ttuu23RokWEkFGjRl199dUIoWAw6HK5FEW59tprL7jggmg06vF41q1b197e3tDQEAwGq6qqVq5cuWfPnnPOOWf9+vWpVGrcuHGFhYWCIEiS9NFHHyWTye7ubl3X29vbN2zYIEnSNddcc+mll0JBg0kGruH169dXVFT4/f4nnnjioYce2rNnz6pVq1wulyRJO3furKmpWbBgQVFRUV1d3YoVKxhjxcXFV199td/vnz59+uTJk2fOnKmq6hNPPGGa5kMPPbR8+fIlS5YYhlFfX19RUZF5+jPq87N9+umnI0eOvOKKKyilBQUFqVRq4cKFf/rTn8aPHz9o0KCLLrpo3759Pp/viiuuOOWUU5r27TMN81sXzDHjiZdfeS7U2ys6S1jmeotvDOCihPEJ2F0ejwdO6XE4HOl0OvPQkQF5GrPuVWCciUUvpbla0zkVQ24YUvj/Nkaf6u16cF0d2tf+8ZoNz+82n9ic9DvYbSf5h5tdDkOQ6SEXIEmStHDhwt/+9reiKBYUFNjjYxgYOBwOTdNUVbU/d7vduq7HYjE4cp4xNn369KFDh6K+sc3q1asfeughxlhBQQGY+1OmTJk3b15tbe3999+/bdu2hQsXTpw4Ec7yppTG43Gn09nV1dXd3X3jjTeOHj3aMAxZllHG2Zd2aXZ1deXm5jY3NzPGxowZ09PTk5+fD42Truu2RQdTMeDCgkGF7W62Byc///nPV61alZOT4/F44LRO1De4gmvgk0gkAqciW5Y1bdq0wsJCTdNyc3OhKBBC6XQa9IwQMi3L6VAYQ6ZpSqJkUUphQP/NC8EDs1IOh4NSKklSWVkZIWT9+vUtLS3Dhw8PBALQEjkcDjTAw0iykwrGDJZAEtYjCNeXlV5T6vhxXcvGbr04PrxNT/6xun1BxIlks5k5X1jXlqMY358adGFC2cHn+CCXy5cvr6ys/N73vpeXlwejWGhoNU1btGhRaWmpz+eLRCJNTU2qqi5evHjYsGGnnHLK9u3bW1tbI5HIbbfdtmnTJtRXt1atWlVaWnrjjTcOHTo0nU5rmnbKKacsXbpUEIQTTzzR6/XOnz//rLPOgi5YVdXx48fLsnzzzTf/7Gc/mzlzZlFREXyOMnwj9lhflmVN0xKJhGEYiURi/fr1six3dXWl0+nKykq327148eJUKrV37154Vfap4qhPyeDBDIfDa9asufnmmy+88EJ4XnvIbnuum5ubNU078cQTq6ur29raksnkD3/4w7a2tjFjxrzzzjuapi1evFiSpOLiYrswDV2nlBKMEMZpNS0KIsHEYhgN3On8dQdidhUWFsKv8Xh89+7dpml2dHTs3bvXNE3TNAOBQCAQOPzc2oFkZYDtPxkYIYswWWhLxsbcvyW5O1wvkmHUcjrVyl6ljhArhtyFLNGjsl9vQicNxYWsMWYefFgPXcdVV1113333nXvuuS6Xy+fzaZomiuLbb7/9ySeftLS0PP7447Isi6L41FNPpdPpVCr14osvDh8+/Pzzz7/hhhtEURw9evTYsWNzc3M9Hg9j7Nvf/vZdd9113nnnud3uYDCYSCSKi4tPOeWU0047TRTFM844Ix6PQ/XKycmRJOnMM89cv379lVde6fF4SkpKHn300fz8fI/Hg/omzgVBGDRoEHQXlZWVixcvvv3224PB4A033FBYWLh27drt27dfdtll+fn5DzzwwMMPP/zuu+/W19dXVVVhjEtKSmBQBL0HQsjtdvt8vvz8/Kuuuurmm28uLS0FJwwhBN5rMBiEvuiee+657777TjnllLPPPvv6669XFGXkyJFjxox54IEH7r333iVLlqTT6Ycffjg3N9fv98PY1O/3BQM+izGE0OCSEoIRZYhgzPpW7n3TKCoq6urq6u3t7ezstGcFYrGYaZput7usrMw+qjt7tRxqZMMQMykWTYQFxIilYoxSSO5Os1+ub16tpfxpX25Sjim6KqmKIbsNpym3SYLD0h09LtmjO3XDFHPaHh0fmFVYetAlk9DWhkKhUChUXFwMjfHll19+++23jxo1yuv1FhYWdnR0nHnmmR988EE6nS4sLAwEAuAmam5uNgxjyJAh0OrD2EMQhFgs1traCp+DnQZtOfwLH5qmmU6nYY2DKIqtra3pdLq0tFSW5XQ6Datd4KxJSmkqlXK73bA4Yu7cuWefffZFF10UiUQGDRrU1NSEMS4tLaWUVldXC4LgdDoff/xxRVF+//vfg3UHWVIURVEUXdcNwwDbad++fYqigDEgiqKu62Bwgt0IRqaiKAihtrY2wzCGDh3KGJMkKZFINDU1FRQUQD8MjQtCyDQ001SxK6hYpk7Vd+tC7zTJL5zjK5IwJt5vlFTsdSupVGrPnj29vb32/AFCyOVyDR8+vLCwEAb9A5o+ztIJAEvrMUIobFhhPSkYFsYOjE0G0fqpwBASELWQAEfTmxRJDinPQZwIZ9muJZPJq6+++ic/+cnMmTNBAG1tbRdeeOFHH32Un5+f5fNkz6FalH6f2ycbNzQ0/OpXvwoEAhUVFd3d3RMmTPjWt74FKyaeffbZxYsX5+TktLe3P/HEE6NGjRIEARZ0Ha1cHeZKxhjDOIRYgGmigWOy8qcdLRv2tPzi3BNGsTiWgwh/48wwQNf17u7ucDisaRrG2O/3FxQUeL3eI0ttwCHzDMRIxtL7g6SI/m/pN0VIziJNcFlQShsbGwsLC8GgQggZhtHU1DR48GBJko6g2h0VoLsDEzSVSm3ZsgWc9FVVVXl5edAtUEr37dvX3d1dUVFhDxzhT19NJhlCKYScZppYlq54/rWrdVtt481nnzRYSCHJ8w3fFg6TwvbrOLJ1Q+gIpGLt35XKGGx1zEjq/34i+xtGxpCQRRMJxlhma5q58NM0TV3XwXT56oFhlZ0le5YQRuQIISh3QRDsrt9eGGb7f7+KfJoIIw1hlWFnUhd1g3oUQUBpQXKi42m7wVcMy9hwYTsbj+ylDLjZE/om7g+jMPgbpRRjlM3eLqiFMJKGx4AaaS9sAcP9mABVH2MMpq2maTAWtxdyQ59ju7kg/7CW/sharyPKJcIWYrJAMRKo6mEuxERGka44yFcm1uMPu3sH7MV1R8bAYxbTAV5/iJUVUKtgwH1km5m+eo7nTFILaYJpobSDUVEVEXVYMklK2PuN9IBlT+aiycOvChu4MY0P9Yt1iC8csmXNnKI+bqtgJsdzJrGACBIQciJsIQdClGIBS1wm2ZHNmz1qkfDZIaRymJ1Fpml2d3fzQ12OBgxhnVAZMckk2MQ6wqZIkUSJhQWul8MAprWmacFgEGbADsWAe5VD1Wt2iL8Ih5CKbT6CDTbQbHA+D8OMChbGlsBErMkiJZZMqWhSpojf5GH94WF9W8ezGevz81U4nKzgzTmHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVhw1qXCnM+c/my81rwLfhc2u9jTiV7mclsP5yjhyqcAOk36LZ+05+KORNw7nOOJL9SqU0lAotGPHjng8LopiRUVFWVkZOr6XFXI4R8aXkkpnZ+ebb76ZSCQg7IOqqpdccsn48eOPYv44nOOEgS+X7BuZYIy3bt2aTqfnzp2bm5trmuZf//rXFStWjB492o5KlrltkMP5WnMk9dgeuPf09AwaNAhC1CmKUllZGYlEIMRlZqzEo5xlDudYMOBeBXoJGL7DkT1wrALEvTRN0zAMp9MJ8Ur4AnvOfwwDD0NhWRAl8eOPP965c6dlWX6/HySRSqVSqdSQIUPmzJkDp71YlgWhTQ+DrS6UsSM3mUy6XK7MjcTpdFoUxcy4LZRSVVUh3pdNKpVSFCXTL6frOqUUAm/aJBKJfvt4UqkUROg7aMY4nAE3+WBZbd68ee3atclk0rKsjo6Ozs7O9vZ2VVUJIfX19YsXL4YAWYeJSGT3SNddd93UqVNXrVoF3mfLsl599dXJkyc/88wzdniHurq6008//YILLujq6oJTGnVdv+OOO6ZMmfLBBx+gvpgv77///pQpUyBKPPR7nZ2dl1566VlnnbV37174RNO0X//61xMnTnz99ddR3zEvK1eunDp16ve///1UKgWRUe2Mbdy4Eb7Id2t+wxmwVMCgCoVCEJ3RNM38/PxLL720srLSDh4DkacPH5Tfjo350Ucfbdu2rbq6GrZuIoSWLVtWW1v78ccfQyBjhFB1dfWaNWsWLVrU0dGBEKKUJpPJf/7znzU1NWvXrrXTXLFiBQSlhxqPMW5ra/vkk09WrFhRX1+P+na9LViwYM+ePYsXL0Z9yt+wYcP27dvff/99OFqIEBKLxd5///1t27atX7/+6xIlg/Nv5Ug8YIQQWZbtgFfDhg2bNWuW0+ncs2cPHItlR8Q6TDpQ8/Ly8u6///5du3adccYZduLf+c53dF2/7LLLYPxDCJk6deoPf/jD3Nzc4cOHI4QIIR6P54EHHli3bt1ll10GNiFCCE4amTVrltvthmhJw4cPv+uuu9LpdFVVFQRPUhRl7ty5w4YNu+GGGyAnjLHzzz9/8+bNY8eOzc/Ph9jyOTk5P//5z/fs2XPWWWehDOcEF8w3lgGPVaA2v/vuu8uWLVMUxTCME0888eqrr169evV7770H+ikoKLj11ltlWc48ZLQf9iEKEPsLeiRCCASbsyODwSm+YP9IkpR55B3Ez0Z91hcErYN+CY6FALmCEQh+OTtOJFwJx8eBBwK+aAfCgz7TDgJm+765VL6xHGGkUKhz0E43NDQsWrSotrYW7P7MxWDo0LGzbD3YCcLPMLDO/BmAqgyf2EE14TI70J49mrclaqcPgrGzB1fCZZl3yUwWZWiDK4QzMKnYXZDH44F6BmtbPvzwQ4QQmF66rvt8Pvsw68NUssw/Dagu9rv4wO8eKrUvjsrBJcE5BEfSq5imOXHixK6urqamJmiedV2XZdkwDEmS3G73mWeeaR/adrQzzOEcG45krIL6DmTTdd0OowTWP1g49rlt6Gic7M7hHA/8W+KA9RsKH/X0OZyvHh4yj8PJCr5Ai8PJCi4VDicrjtmYG+YEk8kktwA5xxaYaHY6nYdfGntspGKP+yORiH2o0jHJCeebjO1zgnUbh5fKMRvW2wtP+GoRzrHFPpbw8PXwmBlgdmAkvveLc8wBu+bwZ3dyZzGHg1AWB33yFp3DQSiLuXIuFQ4nK7hUOJys4FLhcLKCS4XDyQouFQ4nK7hUOJysOPIpSAgNkRmV2A6WdfipHA7n68iXna3XNG3Xrl1NTU0+n2/SpElutxtlMZvD4XztOHKpwCbhhQsXLl++HJYJ79q16zvf+Y7L5eKbhDn/eXypscqePXtWr16NMZYkiRBSW1u7fPnyLK2vwy+oOfCvB119DJ9kszDZvoAv5OEcGV+q+W9oaFBVFSJNgkL27dsHwcG+8LuMsT179uzatWvOnDmSJEE4C/gTDIHsURCYc3ZMPQhpCSEvIL6eaZqEkObm5k2bNl1wwQWSJGGMDcOwg31pmiYIAvwKCzRBXaIockORkyVfqleBKgiVGNSiqmqW34UY4S+88IK9/hmiiomiKMsyVHeUEZtPFEWIPCYIgizLoBYIeg//1tbWPvvssxC4FUJ0gxgIIU6nExb8QzQZQRDgc64TTvZ8qV7F6/WapqkoCkQNhmB5WXYpCCGI522HQaKURiKRN998s7W19YQTTrjyyisbGhrWrVt30UUXCYLwl7/85eSTT47FYps2bWpubp4zZ05JSckbb7wRiUTmzJkzZ84cUBr8ixCCuGR//etfN2/ePH78+KuvvlqW5dbW1ldffTWZTF566aUnnXQSdz9wsmfAvUrmwGDUqFFer9eyLHATE0IqKyvtWKmHT+fACJGWZf3P//xPU1PT7Nmzn3/++Xnz5nV0dDz//PNwxzfeeKOxsXH79u2/+MUvIL74vffe63Q6Tz755AceeGDnzp0OhwNjrOs6xGWVJOmll15asGDBrFmzPvzww9deey2RSNxyyy2yLI8aNer+++/fu3cv1wknewYmFRgeAAihwYMHjx49GmwnQkhxcXFVVRXIBq6EKMYHpmOHJLaD2ENXcPfdd1988cUYY7/fX11dLYoiCA8MM0mSDMM444wzfvnLX1ZVVf3yl7884YQTRFEUBGH37t1gd8HACWMMHdSECRP8fn9ZWdnChQsXLVrU2Ng4evTowYMH67q+aNGiL198nG8OAzPA7CiSGOPe3t6VK1fu3r0bBtbwyT//+c9Zs2aNHDkSIswffocjnDBhHxwpCMIbb7xRV1c3Y8YM8A1AfFfLsuAEL9CVoihwotDjjz/udDrHjh0Lth/Izw5+aRhGNBrdu3dvZ2enaZrnnHNOd3e3ZVlLliwhhEyZMgXOn+BwsmTAYxWI4d3V1fXXv/61ubkZIswLggDHOdTU1DQ0NFx88cWTJk3qF+s+E/jcMAxd1zVNAw3EYrG//vWvr7322tSpU9esWaNpWk5OTiwWY4zFYrHOzk4YmsON2tra1q5du2zZMo/H87e//Q3OkwB9wgUul6u8vHzGjBnXXnttZ2dnIpHo6enx+/333ntvcXHxrl27gsHgly08zjeJAUfCh9gWH3/8cWNjI5xwYq9ngeGKqqofffTRsGHDcnJyDh+R3uVyNTQ03HjjjeCbuuOOO6644ooHH3xw2LBhW7duHTZsWHl5+eDBg7///e97PJ5UKuVwOCRJ8ng8GOPS0tJx48Z9//vfd7vd4XBY13VFUTo6OubOnQvp//jHP77vvvvuv//+zz77rK2t7eqrr77qqqtOO+207373u8OHD+/p6XnssccKCgq+dAFyvikMeG89nMP47LPPtrS02Eei2sGK7O38t91229ChQw8TZYIxpqpqW1ubpmnw67Bhw5xO57p160RRLCsrMwyjsLAwFott3bo1Pz8/GAy63W5KqaZpeXl5CKFEIrF169ZgMFhYWIgxdrvdra2tuq4jhDDGBQUFOTk5bW1tdXV1gwYNqqiogExu27YtEomMGTMmPz//S5Uc5xvGgKUCLqbNmzd/8skncEo9HLWF+o6JdLvdkyZNOu+882BEfijfMUyMZH4CMsucdgTDLHNqEvXNtGRGRbLnKDNl2S+4eL+kEEIwVzOgZ+d8kxmwVOwJwVAo1NbWFgqFdF2HEbyiKH6/v7i4ODc3F+qlfeLcgdinTaC+w7TAb2Z/aM+32B/aFd12WNvSAp1kXmAnYq8kgAQty4LFAYc5fI/DOZAjOV/FXlFyqKpmz98fZkY8s2fIrPqo70RIdOizF9khDqXI/NmejjzomV6Mn+3IGSBHEgfswDra76+ZdtHh08m0qfDBDiU+TFKZFx/qOJd+Hx5KY5xvLJlV6/BV4piFzMsc3vDVvpxjRfYmxjGOWbw/E7yB5xxrDvQz9eOYuYBAzaFQiK9Z5Bwr7P7Esiyv1+tyuQ5z8bH0llqWpaoqTK5zOF899hyDaZqyLB9eKsfMAONja85xQpbHMRxjqcACfj6/wTlW2PNvXzjPduyPIuJjFc4xJLOlPk49YBzO1wtu+XA4WcGlwuFkBZcKh5MVXCocTlZwqXA4WcGlwuFkBZcKh5MVfMcs57gmc4EgQQghhhBDCBFGEEIII4rQ/u2yiOG+bxCEMUIMAl1RjBBC4pftFbhUOMc1ArMQQiAPjHGfVOAHhBAmCGPGbAlZWEAIUYQIwghTxDDCCKGjsByES4VzPMMwM/erApO+Go/tfxCiiCG8f8UJ7rsMMYQoQhgLGCMGMvvSWeFS4RzXMIz3W177pYIZwgghCyGMEEEMI9bXxWBbEfAfZnc9fZ3Ll+FLrQGzg0XY8eftsxm+ZLY4HIQQQ8hAiDKGEbIsSjARMBYIYgyZGIl9oxeMsEUZxdikiDCLEEKpScA0g4ENweKX9mB9qV7lwEXBdrhuDueoYCKGGBMIlgiSCEOMUt0wVS1lmNTQkKEyZjCMZZcXKy4kyj6HsD/ACaIYCQwThJBlMfSlT/L9Ur0K9CS6rm/atGnUqFG5ubl2cAm+rp5zVDCRLiJMjXQyGop0dXbu29vb0Z6Mx5HoZqbmcRDLSsfTSQ3LXYl0S2fPuLHjJk4+cWRFpc+fxxBBfX0P/tIN+FGQSmNj49NPP33eeefNmTMHAuFl2bH065QOs3HlwD9lEznpMBfwTTLHHxlD8wy0ZFtTQ31TXW28p9OJWai9BRu6SLAoBzwuCVkpxnSDWcjtaQ7FFy5fmdRJSUnpmNFV06bNGjVmQk7+IIYljBgWDnzdB7/joRiwAWYf1Ij6QhOJolhUVOT1ehFCcETj/ox8PlxqP6D/sU91hGQhzL4dPg/iAyCEZFmmlELQV9S3BUcQBMMw7KPw7ERgRxt8EWJw2JFa7SshD5m/8qCsXxH0c34s2jf4JpaGEEFEYgwhigQBm8lk/a7qum2LW/bWywgHPV5LVESmUFHRKFUlRyAvPxXpEZGpyEhwyR5TKyzyxiJmUDADyd70jk0d4V5cWeUZVkZcHmZJhGDEEKWmKNh3RgjLWaplwJHwGWOGYTQ3N8fjcTsI6qmnnqooSnV1NQSelGW5tLTU6XRSSuFUiYMmBYeoQG2GQ4sgoKuu64wxRVHsbZy6rsMpK3BKKyEklUrJsgwnvUCCcEKLZVmpVMrtdtvnqoI1yBgDMRiGgRCCAy1SqRScFAm64nwVHKxaYoQYJowyDM4hRut31Oyp3rqrerNL0TRNdbrcsqJgihwOOaXrCGOPV9H0lCQTARELWcy0qEWpSTGjeTnBovzCXH9AkWVDS8fDvb3tHYrDN2hQEWOMYMwQynCI/Xt6FYxxMpl877336urqIPKvJEkQ8DuzqTYMIzc399JLLx0yZMhB07Ejeeu6vmLFigULFlxzzTXjxo2jlC5evPjFF1/UNO2aa6654oorBEH4xz/+8fe//92yrIsuuuj66683DOP3v//9Z599FggEHnzwwTFjxtjJbt++/YknnohEImVlZXfffXdRUREckySKYm9v70cffVRfX/9f//VfLpcrlUo9/fTTa9eudTqdc+fOnTFjxoDKgXO02O/VZYxShDHGhKXj0bXLl9RXbxapJloxrzeQTsYYQgwjRhDFlqwQlyQxlJJEB2I6RlQRxLiaRhRRg/mc7rxgbl5+fm5BkdObwySRUmvfvj2frVr93eu/N7R0iEWRKMqI9U39Z22GD9jq2LZt2+7du6+55prS0lIwluzjf+0mPJlM/v3vf//ss8+uueaaQxk20CM9+uijGzZs2L59+1lnnYUx7ujo+NnPfvbAAw/k5OTcddddI0eOLCgo+M1vfvPUU0/JsnzzzTdPnz593bp1n3zyyZNPPvnBBx88+OCDf//736HjSqVSt9xyy8UXX3zllVc+8MADjz/++JNPPmkYBujkxz/+cSKRaGxsvPPOOwkhf/vb3xYvXvzHP/6xpqbmgQce+Ne//sXPkPiKwP1/wzB5IhDErHika83SRTWb1wWcolvCRGGiiPML8uPhWE8k4lIUl1N2yVIsHpFlyety6yrp7QkRQTIppoYVdPu8Dn9RboHXlyMoDtHhVHzeFGG6lownQpu2rH33n2/ffMNcRc5niKGDhLM+HAP2C4RCoWAwOHLkSI/H4/F4JEnKzc31er1erxfOufZ6vUVFRWVlZT09PXY0+/7FhTHYXTfccMNrr71WWVkJJlB1dXVBQcEFF1wwe/bsqVOnfvbZZ4lEwuv1nnTSSSeffHJOTk5zc/OaNWsuvPDCqqqqW265paOjo6GhARSrquoll1wyd+7cwYMHn3rqqT09PagvGrLb7X7mmWceffRRj8eDEDJNc9KkSc8999zo0aNnzpypaVoikRhoOXC+PPa4FDMmUD3W3f7Z/H/1tOwtzvWp8bAikbz8XJGIiuzw5+QJktNCxKJMN1TTUDE1dDUVDnWbho4xwoypiZRLchTm5AZ9fp/XLzvdWJYtzAhByDLSWpJi69X/98oDP3+wo7ONIWZapnWI+nlQBtyrlJeXr1y58u233x4+fHhNTU06nb7qqquCwWAymVywYEFjY+OkSZMSicTq1atnzJhhn1V0IOArKy4uVlXVMAwQeCAQ6OzsjMViwWAwnU739PSMGTNm5MiRN9xwgyiKpaWlM2bMmDdvXlNTE0IoFoul0+lEIqFpmqqqLpfr7rvvNk0zkUj885///O53v6vrejqdxhi7XK78/PzOzk64tSAIJ5xwQjwef/zxxz/99NNvfetbhzIUOUcdqJsZfk/EKMUCiXU2f/rBe5HujoDX6VBE0+dz+4KarhvpNKU4J1iYTKRikZADCZRaDkX2KC4jbWBGHA6nIjt6EpHWxia32z8omB/wBBAWkChhWRIVmSJLUxOaYTCEREn8YN4HwUDwwQd+IcuOAa13GbBURo8effrpp3/yyScbNmwA/9Vrr712wgknNDc3b9u2jTHW0tKiadqECRNmz559mHQyA3vbsWInTJgwfvz4G264obS0dNmyZTfffHNnZ2coFBozZgxjrLq6uqur67rrrps7d+6tt97a09OTTCYjkciPfvSjWCz2/e9//4ILLmCM/fSnPy0rK7vkkkvefffd119/PT8//7HHHsvLy7NdZOAQEwQhJyenuLh4z5498Xg8EAgMtCg4R4DtoMUIYUIs3RQkUU0kVs97j4a7/BISTU12KkR0RFTa0RXJcco+r7+1rVtVdb/HE42HXaKVF/SLTIwlYorDpbgchmX1dHXrqjqstCzPH3ApiiCIgiQTWUIEG7quphNqWvN4/dd/93tNjc0jKkbuqqsZPWq0LCkMCVmueRmwVAghZWVlcEwpOKlaW1ubm5vt04IYY7IsDx482O12H3hWViaZZznAD5IkPfPMM6tWrSKENDc3jx07duHChbIs/+pXv0IIXX/99W+//fadd9755z//eceOHRjjrq6uqqqqhx56CCEUDAYxxr/+9a/j8fgLL7yAMT711FOnTJlCCPH5fKhvAQ5E3ayvr3c6nT/4wQ+uvvrqU089taamZvr06QMtCs4RwBDCiO33QTFECDYNbdVnn6Z7u/wyMUwqCiJB2KLY0GgkZRQFgi6XP90WTiTTuTnBaNgQZGqZFEuCQ3J6vR7N0phliIIYzMnJDwYDPq8kSZIkI0IshjCjqXSqvb0trWqK0xkM5uqaGQgGtm/fHurtPe2007PP+YDHKqzvjF8Yx2eeSof6ar9lWYZhHH5yM9PJCw5c1LeErLi4eNmyZZTS008/PT8/v6mpadeuXQ0NDU1NTSUlJQghv9+fl5f30ksvXXzxxfn5+UOGDBkyZIjH43nqqacWL158xx13hEKh5uZmj8dTWlo6ZMgQcC2A7xh82fPnz7/77rvb2trWr1+fTqdzc3MHWg6cI4Eh0WCYaSZKasjUDYR0a8+6j0M737fMcCTajTEVBEFTdQkhPRYpyvG6cgqY7HR5vW63wzRVh1uRvW4Vo0QqQgTKqC4TZqaTMqMFHk/Q4SSWJSBGRCI6FdGjmCKNqKGm7oZQOibIcjBYmIrplooZk5avXd8di2GEKaV2TbY5MO9HMu9mH72dOcPY78ygLCP2wZUwZIeLGxsbH3nkkZKSkqeeesrpdM6ePfuKK674yU9+YlnWueeee9555zHGPvjgg+XLl1922WXXXHONnY6u69XV1cFg8KmnntJ13efz/eY3v4Fj7+ECj8czdepUkM21117b09Nz4403SpL08MMPl5eX8/n7rwIMFYJgRDBCooDiPb112zfLEiaikEikKTHiybAgOQRCTD2eFxyEkGlZyOmQDFXUdTUcCnsGF7g9PpaKWczSDN3UNWQxn8cb9OXm5eSKDqfJkEQEp8tliaJq6t2hbt3UJcGKhrtMw6wcVSYKzOUUc/yeZZ8tnjNrjs/rg9nCQ80B7s/7ERxwl0wmP/zww6ampswZwMwLXC7XeeedN2zYMJSFVBhjmqYJggBT9SBxh8NBKdV1nRAiy3IsFkMI+Xw+6K9An7IswySmfQtN00AYkI6iKKBYQRAopaqqiqIIk4/QJcbjcUEQAoEA+JS5VL4KLIQIo9hEiFBNXz7/3XR3LdK7omqaIOJ1+iydypJLNy0LEZfPH9dpMpESiYQplkUSjXQHAz6XU9bSIWoZAkIeh2KohpE2BhUMLiooET1+ye1z5ORJAb8uop5kz5pNK/41/72OcOy8ORcYaTph7KS9e/a5PV5BEuv31s+efvbs2admHowFHORcxIFKxV54b1tNB4IxliQJxtDZrAezDzTNPD0YZQT/hvpNKYXpfJjjtw/H6zfmAd9a5icowzKE9EFg9u1g3MWl8lVAEcKIIQtj1t1SP++t/x2W71Tj3b26RQ2ajMRdssvn9hNB8geCFKHmcEckHA36cxHFsiDKIqaWYRoqEjW/x+13ucyUlgjHcnMKi4sGO51ey+11ePzOQBC5HEmmNXY1Llw+f8PmtV3dnQRLkZ6EQ/LpqmWZKJ1OE0EqLRnz+uuv5+TkZE6jo4NJZcAGmO2tUhQlyyu/EHtll+2e2p+5vjGGbdRldpEHpg+X9Zv0zEwwcwlZJnwB2FcGpYgySpklS9bunRvVZLfmzvV7cjWD7N3TQFVSlFcUC8d8Xnc4lCYCIYzm+LwBvzedSKvJpOCQRYJUQ3O7HYrsUJNqb3un3xPIyy305+SLilNzuojDwUTMEE2l463tjS3tjbJbKBZzNM1yOpzJuEUZRphKhpSMJ9etW/evf/3rBz/4wUFP2M3kONpbkjnmOfDzg/4p+2Ttn3nXcYwRLIaYSEhPR0vdjo0C0pPRRCpmJeNaNJIoKRlCiCxKjt5wOK2qoqwEfAFFkpFFtVSqs71V15KUqjl+t4SFRCTa2ticiqW8br/T7ZVcHsHtFT0OyePAkqDqqUi8p3bP9j2NO9NmFAtMccoev9eXF/Tl5voCuU6XVxAUjNGbb76ZSqXQF51JehxJhfNNgDJNEBgRhH176ro7WwwtmYinwt2pUG97MMeVSPToRswbkDwBycCpmNorYJGZKOD1i4RgZGFkBfyuYI6bGUZPe1eos8fjcHncXiIrTJKJ04UdApYwkbGF9Gi0p7F5TzTZHUn0mJSmVC0ci0eiiWgiHYmrmkFMS0QM7du3r6ur6wtzzg0PzlcHQ4xhizFKDbO5oR5Zhtvr8CAP1qVgjtPhkEPd3dF4oix/uOCQUj0RomBqOA3daGhoYKaZEwggZsgSiccjpqqHOrupqrudbqfiRIiYCMuKQmSTYoaRqVtad7grmY6JEnG6FcOg0Xg6rRLLcibTzExTmcmKwyurptPpMk3rC82NYyYVGE+rqnqodWKcry/gOHE6nejzMwoIYYo9AqLJcFuqo32It8gtUJeEk2Z3juIxzPSQ4oCqJ4kQESUjGGQiSdMIQmoqEk+6PF5/Tq7LQSLhODO1cG84FuotdHuDkqhQS8TEEhSVOCgSGNEtFo/TcHP3nmgyIgkeYnpTqhSNpZNxk5pmKoEYFUWBICZLTp/s8qc0y2JYwAjO8IKs9nuoYykVwzA6OjrAqcVPRPoPIycnx+VyZW4EBDDCBKHuzlZDSw7KzSF6kjDmdDkQdjMsO2RFFJyYYREr2ErGoulcp6/QmWshmlKTPm8BpkY0krAMbV9LWygeL8rN1bBFZYwcAlMwlagoCBRRTdd6e7q6urp1zUQWiYYS3R16Z3vEMkVqKchSMBaJIDoUBVkmQiwcDquq6nE59ucRHaUpyKMC7HUZOnSovSLmWOWE8+/goEcXYoQYowjTVDKCmCqJLofs7OnqEgQFm7IsKNHehEk1QcKarmNMnHLAooZlaV63YpqqmohoqQSyjFQi0dMbZohYRNAQMgRGRYsIGkNpCWPTMkxd7Whri4SiInYkIolUWu9tt6ZOmn3ChBMxkru7w5s3bSktLRUl4eOPF+iGlkonY/F4hlQOwjGTCvQk9szGscoG59/HQRdAWKaGJBrubkNUw8wQRRkRTDESGUslk4aRIhJDFtbVtCQpgiTJMrEsJImIUEc81EUNIy8YHJRXgCxPS8M+t+KVJAdCRMBMQqZAVcHEaTURC/Xua2js6gxHw5qRFsy04sTKqdPmjBo1GmMcCoclhE47bXYkGlm9ZoVl6YyZ0Wi4uNDes3QQtRwzqdizIrw/+U/loG9WFkXEUql4VKCWTHA8GjVMy+NzUkuL9Lb6c9xOpywqAkNElgXdSGmapEiyZZlM19KRiM/jy/Xl5ASCuWOLm9xBSg2vwy8iWTCxw0SChRkzdDXV1d21r7FN1Ukkapq6G1MiCRI1hXAoIoiYUd3rdRBiiSJCzKLUyMnxO5yH3DACcA8Y56uDIYQxYbqpiIJTlvR0OhaNJdJWTp473N1BsCkKNJjjRgQJhJqWlU6lTWrJomRoandbm8fhGlJUEvQEZeL0+7ze0Z6kmhJdDkn2YOLASEYWsUxV09T6hsamtq5wQo8lMLNkbMmqmiKCQASECaVMN6y0y+NUdXVw6aBEIuH2OEThCyZO+LwK5yuFIUQpJkzIC+RihvzeHLfb39bebWjWoIJiRXJaBqIGdcpOZqBUPOV0umVJDvdGPE7X8NKhuf5cgUlOyS24FGdecNDIkbll5XJ+IXL7LdlFsUQRiseTe/Y29kaSnb3JRJqkVSmdllRdM5nBCDWYGiwIjKgYjkVcdcL4WbNnYoy6ujojkfDhc3689Cr7N44OxBg7umuBGTR5DFGMMGMYMYoJYgzyhBGj+08oYJghhAQ7yCdGCDFM0f4oIJgiRihCDCOCEKKIIoQIEuj+wAeIgUNyf5Cfb5bxiRGiFAlEkCVJZTQUiro8flFydra2lpcUy7LbsNT21h6H2+HxeAhx5OQUIiTsrd/LVG1k6dCA1+9SnAzJlBEkS7LHzRxO4nAhUTCIgLGATItqeltH177mtkTa0nQsiG5iuQ0DMUJXrF5RUBgIR7oVRbAsOr6396yzzl65akU0Fo1EIg7ZcfjMHxdSMU0T4hhhjCORSDgcDgaDwWDQ3jzQb9klLIi0HZEwMyMIQjgc7u7uhusVRSkpKYFVm1+4ZJMhlkJpyXSKJu5yoICZlg213eXO7RE1zVT1thxJUgvzXLKZQq0uXUZ4MJWkNDZEZLg1AVE5qmADM6+lO3WJCsl4exJ3uhTRSQbrNNc0BGIghx+lKcOU+WRmYhJiWGZWgHzpAKFfIyhCKhG8giHguIGMtDPQEtILAi6Pk2gSjjLLwth0eQ1Z7kimJVnILS4Kt7b1draXFxd7HLJTURCmSGKGYDiYTIiLSW5LdiJJFDEmFqW6EU+buxq7Gtr1ZMorGZJiSRbGJkkTBa9cs5ZZmAhiIhErKAqceuZZtfU7t+3a5Xf7BFlxO92QyUMF0jsupAKbEw3DWLJkycqVKy3Lcjqd06ZNO+WUU2DBbz8XGUQTt2OK24sgN2zYsGrVKtM0VVUtLCy89dZbs1xajxESEMEYMQiqZmiYSW5djH7aLrweTulthlOITigbfuYQYcaQtIKjVCpgCGHCkIAwoRhhhBwWUUypq7m1481eabNHSFnYTDqDoucyRfqWJbsJwthiFtkflT3z5INvEBghTARZcama7nH5UiqNhDqK8gNMFhBm6WSysDAfYdq2p3lwaYkoCqauyrLg8XicTidCmCJMiCQrLolgghAjCAmYEiyKgihi3cQ9oVjNzr2xhJpKU8HExLIsxHRLVTUVUaIoLllyCsSRSqoN9R0W0zQVRy1129aa8aOqDp/zYy8VWF0vimJnZ+fy5cvT6bQgCJqmzZ8/3+VyTZ8+PbNvga+ATuwoeIBlWTNnzqyoqJg/f/7u3bvT6bSdPsrCtJOYQBC2BESQjiSGk3J6c2z3X/ZMqB2V7/Rh3extZp3trUMrhtI8izIkEiQSgSFMRWxZCFvYbaLUqu7mFztcAX/p9UV4dEpLqsnPzH1vdg2rLg3cK6p+jDAhpoWIgLCI0f7zpL45YIQEhhCWvbmDRLFOEjExk4hpPk9uGqFwNCQSrKcTkUhYRowYRqSrq6erU5YlSZZMSnXLkijBSERYEgUkEEoJwiKihFqYYczSVrqlrbu1vZcixaIaoogyEwtUVxNTpk6Nx1K765oIFZEgpVPmy6/8TXYIjClq2vx//+8vF51zYUZO6YHD+GMvFXv+sbu7247LSgjRNK2jowP17WPJrOvwayKRqK2tbWlpoZQWFRWNHj3a6XSuWrUqFoudfPLJDQ0NmQFdvzAXAgwlBEtCKpIwYnJ6WXtud15LUSotxItSThd2aK0dZiggBnUPkbHlEwRCsYAIspAlI4SbzPp3txUOrii6e3BscA9FYYaYa0rAO7a06/cdwhpLmONiWFUsxgTMkEQYQgML2va1ByMkUoqI6PTkGUhK9nYTM+WUSSwWsWSHLCHGqKGm/G53jteDGQ519/Z09QwZVCwrTizKRHZIDpcouwRBJgLGmGJMsYBFEVvUshjVLaO5rbcnnEqmLYuKGBFJYJqZCOa6b5p7U03Nnr0Nr+gmk0SH11dgGCnTsDzuHGrqfl9ucfGgvmyy42u2/kBcLpdhGLDpCnqMYDCI+jbc2yMT6GHq6ur+9a9/JZNJCHW3Y8eOZcuW+Xy+3t7eq6++OhaL1dfXw7eyvj9BGBHMXIhZCDMDOZstKeayAp2WlBawz2HhuKlFkOZURI3RgGGJiOwfmxNEEOre1Sl2seJf5qUGI4HmBBOFSGC97pTvFHfvZ80dy/cUnzpRU6ibEsNClIgKtRj5RikFIYREjBESvHmlPTFVTKsOwjBiKVWTZIkQ7FCcTocDU5ZOplPpVHd7t8/lD+bkS5KDiLIgy0SSsCAgTBhGjGALMfC4MIZM09Q0rbWrN6mZBhWRIFFqmJbOEHW4JItq0WgPwpYgiERgAiGK4saYqmpCN4wJ48fn5Pi/IOdfTQEdBnscIoqiJEmZv0IYMdjca+sEIdTY2PjWW28NGzbsvPPO8/v9GON4PL5kyZLly5dfdNFF5eXl4XD4yiuvhHFOlqtmGLYwEzHCiiUmBKJTSiKqgj3OlMIwdWkOoruQ5MGqU0Bel4WIqFIsihRjRBnRCXKGGqNOZ542MomRy2OISKamqMrUg0SkVJH4R7GUaiAFI4tSUTCRqDD2DetUEEIIE8oYcQYHpZgj1dmTI1N/II/JzlA06vf5PD4fYbijtYOaFsHEMvHQwqFeV5AQhcgKURRKEEYmItQkEsYEEZEhQi1kGRTpVqw32tbZpVuMEdE0ichEAQmUIZOa1ErJEkUsbVmGJFLLoslU0uGQ4om4pWuTJk+QJNvBcnDP5PEyr2K7rSCuCkIINsejvu3EtqeLUrpkyZK8vLwrrrgiNzcXNuUHAoELL7xw0qRJO3bsUFXV5/ONGDHCTvmL746YhS2EGaICNmQLCZrIkJk0JFVjvqTgSYkyQdjBkGxSp4mdcYSwyRAlFCGTEqQjRBESEFVUFEoiXUcIWZRiLUmSmhMRORlIKpQSEzHwH1tIQAhT/E1b0cMYNQxMkOwcOX5yV08EIzGVNpMqiiZSRJZTutHVGzYodrp8qZQR8OXlBQY5JB/GCiYSFgQsICQyLDIqyZYgIUlCRMJIZCYTLKIntUg8YmFmMWRRzJCAsMQYFrAoYF0SjEEFPj3da+rh0hL/6bMneb10WNmgySeOnzVr6ufzeRBdHHup2KFeysrKxowZYx/5MHz48LFjx0KEfLgSbLDe3t7m5uZp06ZBqArUpyVJkqZPn97Z2dnW1gYxZcBFluUCM8ooQ8hiyLJEyohpUV1LWsQwCNEJSUtGWk7FpUgEx1VBM12miUyEGDIRMg3YBptfkmtFDX91qYSUpMSQhrCqR1GnGbdcn/mDOYWSpFBEEYyg4CTDg9nE/9kwxEzGdMbGjJ/scAWIoDAkSYrL6fEm06qqG7LD6XR5Ort702k9mJuPkIyxhLBIETEpQwSLoiAIiEgCEgmRZEGUBEEQiWRqZntLRzwV1wxNtwxBFGTFKUkKY8QyGcHM73P95Ce3T5hQSWnquusv+/Zl511z9aV3333rb377UGXlSIsah38dx14qNoSQk046yeVyQbzwk08+GUKu2PEi4LJYLEYpLSwstENFor4+p6CgQBTFaDSKEIJQFRB3/AtvjRmSddNCNCygLpfgMWXnbi1sYGahHm/YZVguKhnYSFmiazuWk2JISWKkU0NUNcpwOo28IYu4R7mtwkjT+w1CD9aI1e2LJCShlA2Jrg1Xt9d3/IDmyLRQ91tO7JCRFyFLlAkSv1HmF0PYIoqMsYPhkiEjx540pzVhmTihoNag3+FyyjkBrz8n0B3q7erq9XmDDoeXOdyW6BSdQSR4DENS00hPUWYwiYYwSmLBkiRLJmlsRaPpeF1nd6dFDElRJEJQiolJrDCJKIrlduKCgKu4JH/It791ydRJk0UDsSQ9/9QLhBQr9uc7BBkjAfWd233Ql3Lsxyqob+COMS4sLJQkCaZZ8vLy7AE9rK2E/sfpdDLGEolEZtcBfVE6ndZ1HWJ4D2xHPsZUdogmyTWZpZiqkEbjSOCOEbgaFb6TwOm47m5WZvl8U3KEk2VdjOZphoVzsWXt9seUCHb8aZfn3PJQqZxHShIfNJPO7XnnDemZ4FETqrV0b3p+24RxkzzjczFGIhJon4v4GzdM6XMWE4wwRlgiM84+e9umJam0kR9wBYK58XjK1PRwT293e3dhYbHPF1QUt8PhEEVBEEVRkhRJEgSCEdNNi2mMiYyaFFtMQEhAKJmKN7c0GTpGTBAJthhFCFHLMqnFEArmBlrbmrZt31qQnztm9GiEUDKZ6unpHVwyOD8vH7EvNtSPC6lAwx+Pxzdu3JhOp8Gg2rBhg8/nCwQCcJCL3bHk5eUFAoGtW7eOGjUKhuz2FOSWLVvcbvegQYMOf7sDYQglseRBiJgWkoyUqDK/XDK7OJ5oTWsFounVTFkePLjgjNxEHjJMTdFNwRJJWhssJZOCN7lTzV9Toxbp+5ir7L7hwuIW+gdNxx5JwG4xGbhwVOrb+dTJBIQYo1gg30SV9CFYCAnIwoghVDp6xEmnnla9ZF4ybqLukOJwxXqj0d54fk6+z5Pj8gRcTpcsiaIoCgKRRZkIguKQBVEUBCKISKWSltRFIjpEixp6LBbp7OlipoCpRBA2LJ0wZDFKqUWZpepJf45n4+L1lRWjysuH5+bm9fb0RqPx008/2efzZbOk47iQSiQS2bZt2/r16zs6OnDfMXcrV67ctWvXCSecMGXKlPz8fHtzi6IoM2bMeOeddwoKCqZPn247lzds2LB06dKzzz7b7XYfwfIwgpAuISQIiDg9EaV31b6Wj7cIWyJpZZBLdLpMsefdlsbdzd7TvUNnBlke7UFCLnPk6C6n18q/7kR6Q41s9uY9Xek5Nyf9rSHxTgN1WYpHTOZL8VyiifoIS0AMM5ijx/vv+I3bKs32T+5ZGJmIUUxmnnPBvm2bU7rpsLChWfFIUkKSw+1xSA6H0y07nQJBRCCYIUEQZVkmkkwkUZBEzLAsOTQqGClNkqhlGvsaG3sjUVPzEyQgTAi2CGYCEURRQhj3hnvbO9s/WfQJQmjqSVN7enopZaqmwYRENhzLXZDQJ3R3d7/11lu7d++GcYV9NKQkSd3d3YsWLdqyZctVV11VXl5uf3fixImJRGLBggU1NTUQa3zPnj3Nzc3Tp08/sijdmDGXyVQRWxiTZmvvi9VoYe/QRL6sF3TkhHWkS8xVFHLQpanuTXt3LGkefv0E8SSCRMQcghSKNr/XbFT4U8Fc4aONpHKCWRYgw9GQIRRb6aiieREu1pEoeRDCBH9u5HgcjRS/ciyEMBLyBg+d8+2rV388T3Z70vEkIU5JkGTJIYkyY4wyRghisFSVYUGQiCgzWaKSJGABYcmpKITqlplKpbTWzp5IUhWQDyNqMSoLhBDETBNjTCkTRWdbW7eqGh9++NGnn36GKCsvG/70U08LQrYSOGZSsddHbtu2raWlBcSduSOSMQZHosbj8bVr1w4fPtzuKARBmDFjRmlp6fr167dv3y4IQkFBwdVXX11ZWdkv6F72YAM5EMMUNy/dq63uKBWHdOc6QwobGS6MO7SEN4V1LSdJhybdLeuliEcfckKOgDREVNIhO1VWdGchG1KQfmZ7IhTylwWTSEiaksxwjkYRMxG1mPR/Rtc3zu1lgxESGcOMICwhLGCBUTrm5Jmi4mrZsy1YIMQ6Q0w13E6Xw+mSZNHhUjBhzDQxJYQQhAUsiFhSsENimGAsSYpCDGaoKJZI7W5sVbHIrDRDGGEiEIkyWACFDZOmUtTvLxQEt5pKUUuVZem73//B6NFjB5D3Y7VZF2ITE0JisRisLEafP6AY9cVNFUURzkLJDK9q22OqqiKEHA5H5qpK2xOQPZbKkECxaZmNOmkmxFJUF1N9zGXipMOIK6rEdK9qKaZiSq60UxSGWy4smjgl6A4hJps5aUtQHR05eg4TBawJmoo0FxZchoMhISEi1/+tkfzcOOUbNWZhCJnIwogQhhFDiDGEKMMUIXPPxtWhtnatN5Lq6XWKouKUXV6XJ+AjkoOZpoxEl+yUHE7idiKXgh0yJRQhSRZlrKbURHjVxs0vvvPRrvYoNVKYiBSJFEumiTBjzDDTqeToMWM0Xd21c4fbrYgCu/3Ht/z41h9hgkWUbT05lhFb4EBgv99vj6j6dQiZjuB+n9u9B0TQAVcY6vN3ZeMg/lxmEErLmGKGxDSuVFilQpDpQEkXipko18ecPsuJGKIEEWLIOCWhXsFiJF5qubyaHHYGRIGJBkJmfsJl9iLmJiyImSQizAhGRJVxCqEAQqTfAu9vlE4AEyEBqh1DjDILYyaIBsLDxkzQdSZREeuWlYybuo6YwpiFCJIVh0uUJSJjgSBMLIYRRUgkGCOLWdQy0rqxu6GpKxTTLeQSGRGxSbFqmIgRjARMBIfTvWPHHkKYLLtNw/ju9df96OabMcHMspBAsnwPx3hvfb863T/Ax+djDdscqIQvGXQYI+QiCCEBIR/abyCJBHkR8ohM6NumBRFHRIS8CHkQQciLXBgzFMAiQgxLyIkFhoiCMBEQcfV9AyPZgcRv9sBkPxghBxL2T14ICAtERIghJCAx7c4dNmFKZ/VOQWXhhGrqGkPEwohhUZAdlqwIkkQpwhhhygSGLaxIJpNNI2Ww9pS1ubmnM5yWBbdbUBATDSabOhNFxbAsSjERRMUlUMsgCP/g+9994L9udygSQxYmA9hdd1x4wI4HCEIHlJqw/7PPGUwZv+/fcrL/q/t/w+SALxGuE5sDKyaUFUHI4fENrxrfylB3b7eRNhSdOqjgFGWHKMtEFLHAREwxwphKAraYySzDMk1VS+/eW9/Q3EJEybKYxigjloktCzFm6QQjhk1qmel0wuNx3XXnHbfc9F0hc3tr1nCpcI4LZISYxQSXs3TSCcwpbVm9MmGwPORwIslJJJlIBBMmChZBVCSSgKlgEmIKAtMtfc+++pSWYgK2LKpiASHCMEISYtQkiDErnYiFh40c+pvf/GbWjFMYtRAmEBZvQA4gLhXOcYFgIYaxiRGVpeKqsb78/H3bqtVU2jKY4BAFQcIEUYxFSaAiQQISiUmZrplWOBbds68hoaYIcRCZ6AZFGBGBMWoxahiG4XM7vnftjT+Y+/1BRUWGoTJECCaIwVq8AfT2XCqc4waMKEImJoRIgeKSE3ILUm1dRrRXtyzKsCTJWMRMRFQkFsKMUiIIuqnva2lraetIq6ooiogyIgiUUcNQDV3NDfrPO/P8qy+/fPy4cYhQiiwsEthojDFBA5xR4FLhHB/g/eFvMEIMIwsRTARX6WBUVEA11UynLF21mIlEhCUBiZhapmZo8bS1t7GlOxTRdY0aWDAxEhwev6d85KiZM6edNnvmuMoxIiLUsJDEMCICRogdYdRfLhXOcQHFFsJIgM2oDCPMmCRYCDNRIS5F8vuQoVHLYMw0mUkZtdKWRXAo3t3c2l1YWFI8zJnnC44oLauoHDd63OjhI4a5nU6KTEPXGBMIEwQq7A/bvd8Bh9AAV6wesylIDicTE+mkTyeMEUqwwZiFMUWYICQiJFAmYIoRZZgyRLFpUtWgFkmpaV0UJIfDqzgFIiICld+ymEkpJUhAVCQIY5IRIocgdOggRoeCS4VznNKvXuL+f8SH7RUyhHCU1nFzqXA4WcGnxjicrBiwVOzgWv0+POjnR8wRpJNNBrI/yyVzgfMX5u3fdETMgNL8wovtyINHkMLh/zTQIj2Cvx6tr3wZBmaA2eFUYGGvvZgXVtRnhn2AJV6ZgVLtDSqEEF3X7evBc2evLLY3CdsZswMU2VvV7B2RsII4M4QxBKrMzJW9ttJ+BFi/nPmhHQojczfcgYnYl9k/oIxQMv1Wph1qrWfmlXZ4gH6JwJpr+2LGGKwH7XcSoL1CFF6KZVnw7HZxYYxN04RSxRhrmsYYg/Ad8K3Mt2Dn074LvG77rWW+bvsyuCmsDZdlOTO+IVxMCLFXjluWZQcPsaNVwfVwI7vQ8AHRd20wxhAvLrMEDlNpjxZZ9Sp2wRmGYddsy7LgDaG+Kg6f2G8UHt6yLLjYfn7DMOx6YAsDfoYyhYshjoRdCvAh3NowjHQ6nUwm7RdsFzFCCIK8gIogG7D53q7ittrtlwE5h9cGP0A2MnuqTJ3YqdlVHGVIy/4r3BpKw/4QLrAzAFE1bLXDh3bVhARhJ0K/diqZTMJp63AXW/x2NlhGmChKaU9PTygUcjgcdvmASOwXBJXPfq1wWWb5Z9ZdUC9jTJZl+LppmhA/BPU1OqhPxvA27dKD92KaJrxxwzA0TYMqkUwmVVWFz239w0NB+nbO7Vf5lfUtAzPATNP85JNPIKzwihUrWlpa7AARmU2U3fYTQmRZtvcAo75AKlBesOeREALB8qCUMcaSJNm7TZqamuwKB2nC9pWdO3fu2LEDPoSOwv4KpG+nJssyBPm2m0C76bXrit3PEEIgbJ/dh9gNrX0in50HeEliH6ivEsN2Tlvt8Jj27SB9UDghZNGiRclkEuIHwIPjvgg1kILd9EKADnhGjHF1dfXevXsz82z3HvBdKFXYHtfZ2Tl//nxN01paWmCHj503xhhcZjcWkH/4IjwpQgh+hdKA54W4H62trZTSjRs3apoG7xr6ebgFPDu8+ng8vmvXrkQi0dzcbJfJli1b3n///QULFixYsCAej2/durW1tRXqgCRJUPJ28B2hDyht+OGr6VJQllOQdqVxOp2EkLq6uuLi4ra2thkzZrS1tTU0NJSUlAwZMqS+vn7w4MGapkWj0dLSUqiFNTU1uq5XVlY6nc66urp4PF5RUaEoSkNDQzqdliRp3Lhx9fX10EuMHz8eY7x79+5QKFRZWalp2ocffjhjxozx48dDBnbs2JFMJkePHo0xbm9vX7t27aBBg0pKSjo6Ovbs2TNo0KBhw4Y1NTWFw2HTNEeNGuV2u6urq9PptNvtHjFiRDqd3rVrVyAQGDFiBKW0s7OTUjpo0KCmpqZgMJhKpfbu3VtcXDxkyJDdu3eXlJQwxnp7ex0OR3t7uyRJY8eOpZSGw+H6+nq3211RUWGaZk1NDaU0GAyWlJTEYrE9e/bk5uaOHDkS2o6Ojo6GhoaioqKysrI9e/ZompZMJseMGeNwOGpra5PJZDweh8otSVJHR8fevXs9Hk9RUVFeXl5NTY2qqmPHjo3FYqFQKBQKlZeX5+fnt7W1tbe3t7a2jho1ilK6fft2y7LGjBnT09PT3t7udrtHjRplWVZ7e3tLS4vP5ysvL9+4cSNU3EWLFg0fPvyUU05pa2tramoqLy/3er11dXWapo0ZMwakuHnzZsMwqqqqwuFwW1ub1+stKSnZuXOny+WqqKhQVXXPnj2EkMrKys2bN9fV1V1wwQV5eXmiKO7duzcWizHGRo8eTSndtGkTRDMsKSkB1eXk5OzYsWPr1q0XX3xxQUEBQqi7u3v48OHjxo1bunTpjh07oE00DKOmpgZjPGrUKNM0d+3aRQiBalNXVxcKhSoqKoLBYHt7+759+4YMGVJSUvLv1Mh+BtarYIynTJlSW1v72WefTZ06NRwOL1261Ov1rl+/vq2tDSplT0/P1q1boXFat25dc3OzaZpr1qxpbm7u6OjQdX3p0qXhcPjTTz8VBGHLli3Nzc0rV66EY1W2bdu2Y8eOuro6h8OxaNEiSqnb7Xa5XNBIb9q0qbGxkRCyYsWKdDqdSqVkWV6+fHk8Hq+urnY6natXr25ra1uzZk00Gg2Hw5s3b961a9euXbskSVq4cGEikVi2bJkoijt27KipqYFuYeXKlaqqrlu3DuLwezye9evXNzQ07Nq1Kx6PRyKR7du3NzY2bty40el0Wpal6/q2bdsURampqamvr9+yZUtLS4tpmosXLw6FQkuWLHG73Zs2bWpubsYYq6q6bds2j8ezbNmy1tbW9evXd3d3Q8Zqa2tra2slSdI0DSEEltinn37qcrm2b9/e2toKiei6vmzZstra2s2bN8uyvGTJkt7e3uXLl7tcLlVVKaVr1qzp7e1NJpPr1q2rra3duXMn5FNV1ZqaGkVRNm3a1N7e7nQ6nU6nw+GQZVlRlK6urjVr1jidzsWLF7e2ti5duhR6OUmS1qxZ09XVRSldtWrVzp07a2trFUX59NNPGWN79uyprq6uq6uzLGvfvn2bNm2CNBVF2bFjRzqdXrx4sWVZ9fX1dXV169ev7+3tVVV16dKl0BXEYrG6ujqXy6Uoir2/CLoFTdPs4ZlhGMuWLYvH452dnZs2bWpoaIDGd926dU1NTRs3blQUZfPmzW1tbStWrHC73atWrQqFQralfdQVYjPghS05OTlFRUVtbW0jRoxYvXr1sGHDxo8fr6pqfX09GAMAQohS2t3dPWPGDJ/PBxG6MMapVKqnp0dV1eLi4gkTJvT29nZ3dyuKcsIJJ3R0dOzbt6+3t3fChAlDhgxpaWkxDCMYDBYUFIDF0tbWNmnSpMGDB0ej0ZqamqFDh06cOHH37t2mafr9/lgspqqqqqqyLJ9wwgmhUKi2tra1tXXcuHEVFRV1dXXQ9SuKkkqlwuEwxM+HSp+TkxOJRAoKCqqqqnRdb2hoQH2mIDxIZWXl8OHD4RHy8/M7Ozs1TQuHw5FI5KSTTsrJyWlqagK1Q3PQ3d1dWlqKMc7NzYUuLpVKud3uE044IRqNVldXq6o6YcKE4cOH19TUQIn19PTk5ORMnDgxnU5blgWWJyEkHo87nc4RI0ZMmjSpvr5+3759eXl5VVVVUD+am5slSZJlWdM0v98/fvz40tJSMCm9Xi+USTKZLCgokCSpsLAwNze3tLS0ubk5FAr5fD7LsmKxWElJyQknnCAIgmEYzc3NF1xwgc/ng0atqqqqsLCwsbFRUZRkMplMJgcPHrxv3z5N01RVHTlyZDgc9vv9UEqBQGD8+PGmaUaj0e7u7tNOO02SpMbGRsMwbF8LdJg5OTmQScMwqqurOzo6XC5XVVXV2rVrVVVtaGgYNGiQYRiGYZSWlvb29kIYxJycHEVRotFoeXl5e3t7b29vb29vKpUKhULBYND2Kv2bTLIBS4UxlpubaxgGQsjj8XR2dpqmGYlEcnNzY7FYOp1OJBK6ru9PXRTBgGlra2ttbRUEoaKioqury34euDJzOO5wOLq6uvLy8sA8g/ICG1oQhJ6eHq/X297eDkNV+FNvb+++ffvOOuus7u5ulOFDtCzL4/FEo9FEImGaJkLI5/ONGTOmqqrK7XabpilJ0ogRIz766KPLL79c07Suri7DMMLhsMfjSaVSmqYZhmGP8qHF0jRt3bp15557rqqqYNL09vZC8D5FUTwez4QJEyorKwOBgGma4XB4586d5513Xnt7O8oIvowxVhSls7OzoKAAOgeEkCzL8Xhc0zRd1wVBcDqdBQUFgwcPJoTU1tZCJaCUOhwOaHei0ajb7ZZlecSIEfn5+ZTS6upqe+ALTfjZZ5/d3t5uj9Mg/5qmud3ugoKCCRMmpFIpGJHDaFMQBEVRIpEIxrijo0OWZV3XKaVer3f06NEwPvn000+nTp2K+tx34FWzswef67oOAXfcbrfdXdA+jD7Anp8wYcKECRPgBYGfwO/3V1RUeDweSZKWLFkyZswYv9/f2NiYTCbHjRtnmubKlSurqqpycnLGjRs3fPjwgoICe6D17xu6DFgqhBCHw5GTk8MYq6ioaGlpmT9/vsPhGDt2LIz1EUJwkINlWZMnT167dm1NTc2IESNGjBixdu3aWCwGLzg3NxchlJub6/f78/PzCSFut9vv948YMWLZsmVNTU1DhgwpLCzMz8/fvn377NmzBUGYPHnyunXr6uvrhw0b5vF4QDy5ubnBYFAQhGXLliGEJEmCXsjhcASDwcrKyqVLl3Z3d0cikUAgMHbs2HXr1smyPHnyZLfbjRAqLi7OyckpLCwkhDQ1Nc2fP19RlAkTJuzZs2ft2rWCIOTn5wcCAXDRCILgcrlKS0tXrFjBGBs8eHBVVdWqVat2796dTCaLi4vLyspWrlwJ6TudTq/X6/P5oEzsMzAkSfJ6vWCdd3V1uVwuGFIPGjRo0KBBCxYs6OrqmjRp0uTJk1evXt3c3FxeXu73+2HgnpeXN2zYMBij67qek5NTUlKyevXq+vr6MWPG5Obmer1eeEderzcYDEKZwPge7l5SUlJTU3Pqqae2tLSsXr3a4/GMGjUK3hc4BqZMmbJp0yZBEKCCejwel8s1YcKETZs2EUImTpxYXl6+bt06jHFZWZnP50ulUk1NTfn5+Yqi5OXlCYLg8/lcLldBQcHy5ctFUbS9W06nMzc31+fzgXchEokMHTo0Pz8f8gzOA5fL5fV6J02atGXLFlEUq6qqKioqduzYAfoRRbG2thYhNGzYsMrKyu7u7tWrV0OyX4Ef7EgWtmTOADDG0um00+kENauqCtYnuD6hhzVN0+VyMcZSqZQgCOAngTYg07i0P7QsyzAMh8MBbSG4Vmx/tGma9swA6nM6McbsW9v+WcuyotFoY2MjQmj37t2XXHKJy+VKpVJwHAXkZ/v27YlE4rTTToNXlUqlMp8FfCyZDjEgnU5D5nt7e9va2gzD6OrquvDCC8EpZHtvwPFqGAYEX0YZHmeYbbAsyy4NSunWrVthKDV58uSKigpd16HowPADzxKknE6nZVmGRhRKGIYo/bzwUHR2Hw7FomkalC08LBR4ZoAbXdcZY4qi0L4zbexHhrMJVFWFbAiCYOet3zttaWlpb28Hb825555rdyzw4JBDewKHfH4uC2dMAWVWKrs6QewRhFAymXQ4HJme6IFW5uz5t6wBswVgZ92e/bCnCLJ5KuivoXDhrJXDY5sZKMMfv2vXrmg0WlFRAV4akjFRCI6ECRMmOBwOeCvZA6ZOKpWqra3VNK2ioiIQCEBNsjMDM60HDbhx0Mzv3bu3ra0tGAyWl5eDElDGHAUw0KBNx4pIJLJjxw5BEMaOHQv9xtedf4tUYJLRnji3ewD4HBqkLKUCvQQ0e/ZUxmG+C2Y36ju12J6uAWMaRhT2xZAazII5HI4vrM0HPiOkCb2crut2/UZ9UhEEARpveOossWM02zM/YB39W23xo0tmmOl+ffLXlKOzXLKf3qC6iKLY2tq6a9cu6Dph+hJ8o7YdcvhkLcuKRCKMsaVLl8ZisS/8Sk9PD6W0q6urrq5OkiSHwwFTn/Z8dqZOUJ+VghDKnN3LElCgpmkLFy6Eh0okEtXV1ZmJy7K8ZcuW+fPnJxKJbNLUdR2G0fbEbigUMgwjkUjs3Lnza6QTgPWtTvh6ZftQDGxYzxgLhULgNhk0aBClNBqNapo2aNCgjo4OTdOGDh0aj8dlWXa73eAagvF3Q0MD+BAppZqmNTU15eTkBAIBqKCqqjY1NeXm5ubn54MTkzGWTCZbW1u3bdt2zjnnJBIJcA6WlpbKstzR0ZFKpQYNGgRO2GQyCbEnP/zww6lTp+bl5UGP39raqmlaUVERGFeJRCKVSiUSicGDBzudTnBKFhQU+P3+SCSSSqX8fr+u6+FwuLi42O12J5PJrq4uv9/v9/uj0ahpmvF4fPDgweBzSyQS4A5OJpO07yykQCAAXqyenh447GX79u0TJkwIBAK9vb2hUAjcGJFIJJFIgMFt+zlCoVBBQYHb7Q6FQp2dnSUlJaIoLly4cOTIkeXl5TDYC4VC3d3dkL1wOKyqqmmaxcXFtl/7+ME2FL9kiLbjh4E9BsZ40aJFXq83nU4XFBSUlpZ+9NFHU6ZMCYVCDQ0Nbre7ubk5Ly+vp6fnlFNO+eyzz8rKymCucPPmzbm5ualUilK6ePHiQCCwffv2qVOnlpSUpFKpTz/9FM6BmDlz5qZNm6ZMmYIQ2rBhQyAQiEaj6XQaqrWqqj09PSUlJRs3bvT7/fX19UVFRevWrRs+fPjq1atPPvlkmDRMJpO6ricSiR07dni93oaGBhi1b9++HYIjV1dXn3322UuXLvX7/bW1tRMnTlyyZEl+fv7IkSM3bdpUWFhYW1s7a9asxYsXB4PBrq6u6dOn79q1KxwOu1yuxsbGqqqqLVu2+Hy+urq6WbNm2ZZSKBRqbGz0+/3bt28fNGjQjh07pk6dCt7z3t7ehQsXFhYWrl+//pxzzvn0008ppaNHj16/fv2oUaN27tyZl5enKMrevXtPOumk1atX5+bm1tTUTJs2LR6PR6NRcB54PJ6lS5fm5+fv3Llz1qxZH3/8cWFhYTgcrqioqKr6gjPXOV+egVkdYBtMmzbtzDPPbG1tTaVSw4YNO/HEE3ft2nXqqaeefvrpnZ2deXl5iURi165dRUVFkiRRSvft2zd16tQZM2b4/f6uri5YAqTrOkzki6I4dOhQWCEHM4P2vUaMGDFo0KCCggKHwzF16tRJkyb19vbCMFpRFFjAMmLEiNNOO83pdLrd7uLi4rFjx8qybJrmvn37Jk2aNGfOnJEjR0Kauq6PGjXqrLPOMk2zvr6+qalJFEVd1xsbG91u95lnnunz+WDxzuTJk5ubm51O52mnnTZmzBiY5ZwyZcr06dPD4bDT6SwsLISFVeD/AUPO9s+Ul5efddZZMKtTXFw8ZsyY+vr60tLS008/fciQIdu2bRNFcc6cOYWFhTk5OTNmzCgrKysvL581a1Y4HJYkaejQodBd+3y+0tLSUaNGwfzGnj17KisrzzzzTIfD0dzcLIrizJkzx4wZA7330a8anM8z4IUtrA/ct+Id/gQLQqF+eL3eDRs2lJWV2Uv3dF2HpdqiKDocjvz8/OnTp5eXl2OM4/H49u3bR4wY4XK5UIaBay+RtBNBCMHau0AgMHz48DPPPBOOUmF9q5gzPWCEEFgugfqcSDRjDTIhxOVyFRUVTZ06taysDMYzcKqeLMsrVqywHa8gBrgLfFJbWxsKhYYPHw7jbNS3VBlGRDA6gilaTdMgZVmW4RPTNO3jX+xGAS6ApUD79u3buXNneXm5w+EA4dmnYYL/FK6HW1NKoUjtJclfwfTCN5Yj2dr12WefLVy4cMSIEbD+xzTNCRMmrFq1at68eUOGDPF4PIMHDxZFsaioCJZsjB49esOGDYsWLQKzraioqK6urrq6GmoYGNlbtmwJhUKEkEGDBn322WcrVqyAYXE4HN6zZw8MNsDVO378+GQyuW3btubmZtstBp4ut9u9efNmqNPjx4/funXrRx99tG/fPnt1anV19fz5891u9/Dhw4uKinbu3Llz506YAkcImaa5adOm3t5et9s9cuRIwzAWLFgAs3tQNWFaIxgM9vb2btmyBSox6TsTBiEEkxj2ylxY7GRZ1siRI0Oh0Icfftjb2zty5Ej7kHGYu7CnBSRJ8vv9MMESi8UIIT6fb+vWrbCmYfz48XV1dfPnzzcMY8iQIXY74nA4du3aBQ8C4jmK9YNjMzBnMaX0H//4x+TJkz0eT25uLkyiweGM0WjUMAw4XosxBvNuMImmKAqsxRBF0ePxMMa6u7tdLpfb7YbGVVVVGN1Cx9Lb26soCkwtJZNJ8Dh7vV5wyLrd7lgsFo1Gc3JyYOYLFh1KkqTrejKZhPPKZFlOJBKqqtqXLV261OVylZWVgTvBsqxQKCTLcjAYhDk10rcJJBgMKopiWVZHR4fH43E6nbCKCSEEzxsOhy3LUhQFWgqY0YPZPbgM0pdlGVIWRTGdTkejUa/X63a77Sk8KCWYYoOnEEUxFovBog+XywVLVKDQJEmCRHJzc8HItG8EnSp0TaDVf0tl+WYzMKlYlrVp06bKykqv12u3XplThLTv1BTat7PKNl3gLdqmFO3bFocyNj+CxU/79ujZppfQt6fSnpvP9D/al9lfIX3bZmBFN/x19+7dgUCgqKgIZczMsIydj5mTNrRvfyXq23OWuc/MnjEAs82+BvU5ymF6B4ZqtrfUXklgZ9Wew2YZx2CwjE1j0GXBHBGUjCRJ9gkZ9rQ3ZN7eFMSl8u9gwBuGacZuPtt8x5/f6on6Zg9R38knpG+7qa0cWzasbwevPYqA7aC2Huwc2hXFrhNwvb0wxD5wGDqizLvYYrAXcdh3B6nbqzPszZtwF3vUDk1AZhW3nxTyQPv2rtkbNu1Cs9eVZK5jsHNoP5FdjDY0Y8ef3ZSwjKlJu6DsjNnZ4xxdvuxsfb8Gnh1sxUrmh4f6+aDXDzQ19PltvYdK/8twYJpf/i6Hf8xDlYb94r6w/DlHBR4HjMPJCt5TczhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WQFlwqHkxVcKhxOVnCpcDhZwaXC4WSF+Otf//pY54HD4XA4/ylgQrgNxuFwOBwOh8PhcDgcDuerBGOMMe73ybHKzJfkoDn/+j7Ol+S4ffDjNFuHRxAEQgghxLIsxhg48Rhjpmke66wNGIwxIYQxxhizawljTBAE+AFj/HV8LhuMsSiKlmURQiRJUlX1oJfBC2WMIYSOz+f9WnqKBUEQBEHTNEoppRT1Valjna8jgRACOccYw+NAh2mapmmahBBBEL6mjwZAKwCtm2EY7BBQSkVRPNaZPRzHdeYOhWEYkiRdfPHFZ5555vPPP79z506MMTRIXzsg5yD4sWPHnn/++aNHj5YkqampacGCBevWrbMs61jn8csCUvF6vYcSg2VZkUgEOpPj9j0e71I5qAbGjBnz05/+9KyzzvL7/fX19Tt27BBFEWrb1wtbJw6H4+677547d65pmmvWrFFV9dxzz73pppvefvvtn/3sZ6FQ6OvbFiCEKKUnn3zyc889J8ty5msCWwBM0P/6r/967733jucJ8eNaKqIo2hqAvjsQCPzoRz+66aab6uvrb7jhhsceewwqEKX061iToK5IkvTf//3f8Dj/7//9v97eXsaY3++/6KKLfv3rXwcCgZtuuknTNHjAr2Mnwxib/P/bN3+XVpYojs9mZnbyY8UfiCK2AY2ku4WCCGLA2EawsRCDoLJaJCIiWqQO2giKIogYkKBEVIKFgn+AaNJElNjZBFQwiZiYuFl9xcElV3n3yX1FdmQ/VZht5uzs98z5lV+/JEmam5t7enrS1iGwZIwFg0GHw3FwcADBWOV2yi2MMVEUIVjHGHs8nvPz82QyOT4+brVaq6qqrq+vfT4fKov4uUMQhJ6enlQqNTo6ij6yfK2+53K5Hh4eJiYmEEIYY51H839gcnIymUxKkvT1EWMsHo/Pzs4iHZe/kM7Teq3M5XQ6Q6HQ8vJyLBbr7e1dW1srFApms/lryZg7CCFDQ0OXl5dbW1uQxIPVhBBRFE9PT8Ph8PDwcHV1NUKIxyATeHt7o5RaLBb0UegHp4AxFkWx0rv7FvqViiAIqqoKgjA9Pb27u1tTUzM4OCjL8u3tLcYYikWqqvL79QCSJHV2dp6cnBSLRYSQVtPTvMDFxUV9fb3VauUx9CpHUZRPhwV5GmimUrv6Pvq90OE9VldXy7L8/Pzs9/tvbm4gCIE3WyqVfsCtQimllGolby1Sh28IIXR3d1csFm02G0LIZDJx6hrAFlC7ZiMsgnfQf4qiazUTQrLZ7MzMTCaT2d/fHxsbY4xBt+EHiAQolUrpdLq2tra8xgW5GfxubW2VJCmXy3FtLxQw/k0PXJima6mAZ41EIh6PZ29vb35+PhqNut1uRVFKpRKn/rUcQRCy2ezh4WF/f39jY+PXp6IoulyueDyeyWT4vVJ+BrqWCuiBEJJOpwOBQF9fXyqVCoVC6+vrTqcTOlZaq7vSm/0bIMgMh8OU0sXFRbPZrK2D7bIst7e3r6ysvLy8cN1agQPK5/PlixBw5vN5LoYt9JuroN9zXELI1dWV1+t1u91TU1NHR0fb29vat6WNUVV0v3+DyWRKJpN+v39zc3NnZ2d1dfXs7EwQBLvd7vV6BwYGFhYWjo+PkV4no74Jxriuri4QCBQKBTgmGOSBULOpqQmkAqE1jPZVesuf0buUNSilCCEoedlstpGREVmWm5ubfT7fxsYGdCp5jE9gnk1RlK6urkAg0NLSoigKrD8+PgaDwUgkAiv8IghCW1ubz+draGgo92iKojDGYKplaWkpkUjAzalPr8eHVLTG3Pv7O6VUVVVFUex2e3d3dzQavb+/h1uFO6nAbQldlFwuZ7FYHA5HR0cHYyyRSMRisXQ6zRiDOjK/gI2qqmKMP5W8YdwYJl8xxnCIOtQJ4kgq0KiGWW5CCAzeoo9jAD/EXYgiCILVan19fS0fsNWewpiCNpBbwX3+TyilWqJVfkMSQrTWCkJIa5dxbayu0X9G+Ae+/kFNq4NzbddX/rPV+MPsNTAwMDAwMDAwMDAwMDAwMDAwMDAw+IH8A9s8lwmmR9GnAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCjMK93Cz3zf"
      },
      "source": [
        "## Load model and processor\n",
        "\n",
        "Next, we load the model (which is an instance of [VisionEncoderDecoderModel](https://huggingface.co/docs/transformers/model_doc/vision-encoder-decoder), and the processor, which is the object that can be used to prepare inputs for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ahkkeo8_o69z"
      },
      "outputs": [],
      "source": [
        "from transformers import VisionEncoderDecoderConfig\n",
        "\n",
        "max_length = 128\n",
        "image_size = [1280, 960]\n",
        "\n",
        "pretrained_repo_name = \"ivelin/donut-refexp-draft\"\n",
        "# pretrained_repo_name = \"naver-clova-ix/donut-base\"\n",
        "# pretrained_repo_name = \"ivelin/donut-docvqa-demo\"\n",
        "\n",
        "\n",
        "# update image_size of the encoder\n",
        "# during pre-training, a larger image size was used\n",
        "config = VisionEncoderDecoderConfig.from_pretrained(pretrained_repo_name)\n",
        "config.encoder.image_size = image_size # (height, width)\n",
        "# update max_length of the decoder (for generation)\n",
        "config.decoder.max_length = max_length\n",
        "# TODO we should actually update max_position_embeddings and interpolate the pre-trained ones:\n",
        "# https://github.com/clovaai/donut/blob/0acc65a85d140852b8d9928565f0f6b2d98dc088/donut/model.py#L602"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "84TkZP5zz4hE"
      },
      "outputs": [],
      "source": [
        "from transformers import DonutProcessor, VisionEncoderDecoderModel, BartConfig\n",
        "\n",
        "processor = DonutProcessor.from_pretrained(pretrained_repo_name)\n",
        "model = VisionEncoderDecoderModel.from_pretrained(pretrained_repo_name, config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add special tokens\n",
        "\n",
        "For DocVQA, we add special tokens for \\<yes> and \\<no/>, to make sure that the model (actually the decoder) learns embedding vectors for those explicitly."
      ],
      "metadata": {
        "id": "PfTPbvNRCEDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "def add_tokens(list_of_tokens: List[str]):\n",
        "    \"\"\"\n",
        "    Add tokens to tokenizer and resize the token embeddings\n",
        "    \"\"\"\n",
        "    newly_added_num = processor.tokenizer.add_tokens(list_of_tokens)\n",
        "    if newly_added_num > 0:\n",
        "        model.decoder.resize_token_embeddings(len(processor.tokenizer))"
      ],
      "metadata": {
        "id": "CfJMb2o31AA-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Do we need this for RefExp? It came from the DocVQA code\n",
        "additional_tokens = [\"<yes/>\", \"<no/>\"]\n",
        "\n",
        "add_tokens(additional_tokens)"
      ],
      "metadata": {
        "id": "_dnEFkj71UE1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b46s3KR-x8Iv"
      },
      "source": [
        "## Create PyTorch dataset\n",
        "\n",
        "Here we create a regular PyTorch dataset.\n",
        "\n",
        "The model doesn't directly take the (image, JSON) pairs as input and labels. Rather, we create `pixel_values`, `decoder_input_ids` and `labels`. These are all PyTorch tensors. The `pixel_values` are the input images (resized, padded and normalized), the `decoder_input_ids` are the decoder inputs, and the `labels` are the decoder targets.\n",
        "\n",
        "The reason we create the `decoder_input_ids` explicitly here is because otherwise, the model would create them automatically based on the `labels` (by prepending the decoder start token ID, replacing -100 tokens by padding tokens). The reason for that is that we don't want the model to learn to generate the entire prompt, which includes the question. Rather, we only want it to learn to generate the answer. Hence, we'll set the labels of the prompt tokens to -100.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7tWX_qJDvw_S"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "from typing import Any, List, Tuple\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "added_tokens = []\n",
        "\n",
        "class DonutDataset(Dataset):\n",
        "    \"\"\"\n",
        "    DonutDataset which is saved in huggingface datasets format. (see details in https://huggingface.co/docs/datasets)\n",
        "    Each row, consists of image blob, prompt and target bounding box.,\n",
        "    and it will be converted into input_tensor(vectorized image) and input_ids(tokenized string).\n",
        "    Args:\n",
        "        dataset_name_or_path: name of dataset (available at huggingface.co/datasets) or the path containing image files and metadata.jsonl\n",
        "        max_length: the max number of tokens for the target sequences\n",
        "        split: whether to load \"train\", \"validation\" or \"test\" split\n",
        "        ignore_id: ignore_index for torch.nn.CrossEntropyLoss\n",
        "        task_start_token: the special token to be fed to the decoder to conduct the target task\n",
        "        prompt_end_token: the special token at the end of the sequences\n",
        "        sort_json_key: whether or not to sort the JSON keys\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dataset_name_or_path: str,\n",
        "        max_length: int,\n",
        "        range_samples: int,\n",
        "        split: str = \"train\",\n",
        "        ignore_id: int = -100,\n",
        "        task_start_token: str = \"<s>\",\n",
        "        prompt_end_token: str = None,\n",
        "        sort_json_key: bool = True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.max_length = max_length\n",
        "        self.split = split\n",
        "        self.ignore_id = ignore_id\n",
        "        self.task_start_token = task_start_token\n",
        "        self.prompt_end_token = prompt_end_token if prompt_end_token else task_start_token\n",
        "        self.sort_json_key = sort_json_key\n",
        "\n",
        "        self.dataset = load_dataset(dataset_name_or_path, split=self.split)\n",
        "\n",
        "        self.gt_token_sequences = []\n",
        "        self.dataset = self.dataset.select(range_samples)\n",
        "        self.dataset = self.dataset.shuffle()\n",
        "        self.dataset_length = self.dataset.num_rows\n",
        "        for sample in self.dataset:\n",
        "            prompt = sample[\"prompt\"]\n",
        "            bb = json.loads(sample[\"target_bounding_box\"])\n",
        "            # trim float precision to simplify training with shorter string representations of float numbers\n",
        "            # It is good enoug for screenshot size up to [1000x1000]\n",
        "            # For finer granurality, increase precision to 4 for [10,000 x 10,000] screen sizes.\n",
        "            # Update: Jan 10, 2023. Let's try with precision 2, since 3 is taking too long to converge and seems to overfit on training data\n",
        "            for key, value in bb.items():\n",
        "              bb[key] = round(value,2)\n",
        "\n",
        "            assert isinstance(bb, dict)\n",
        "            ground_truth = {\"prompt\": prompt, \"target_bounding_box\": bb}\n",
        "            gt_json = ground_truth\n",
        "\n",
        "            j2t = self.json2token(\n",
        "                  gt_json,\n",
        "                  update_special_tokens_for_json_key=self.split == \"train\",\n",
        "                  sort_json_key=self.sort_json_key,\n",
        "              ) + processor.tokenizer.eos_token\n",
        "            self.gt_token_sequences.append(j2t)\n",
        "\n",
        "        self.add_tokens([self.task_start_token, self.prompt_end_token])\n",
        "        self.prompt_end_token_id = processor.tokenizer.convert_tokens_to_ids(self.prompt_end_token)\n",
        "\n",
        "    def json2token(self, obj: Any, update_special_tokens_for_json_key: bool = True, sort_json_key: bool = True):\n",
        "        \"\"\"\n",
        "        Convert an ordered JSON object into a token sequence\n",
        "        \"\"\"\n",
        "        if type(obj) == dict:\n",
        "            if len(obj) == 1 and \"text_sequence\" in obj:\n",
        "                return obj[\"text_sequence\"]\n",
        "            else:\n",
        "                output = \"\"\n",
        "                if sort_json_key:\n",
        "                    keys = sorted(obj.keys(), reverse=True)\n",
        "                else:\n",
        "                    keys = obj.keys()\n",
        "                for k in keys:\n",
        "                    if update_special_tokens_for_json_key:\n",
        "                        self.add_tokens([fr\"<s_{k}>\", fr\"</s_{k}>\"])\n",
        "                    output += (\n",
        "                        fr\"<s_{k}>\"\n",
        "                        + self.json2token(obj[k], update_special_tokens_for_json_key, sort_json_key)\n",
        "                        + fr\"</s_{k}>\"\n",
        "                    )\n",
        "                return output\n",
        "        elif type(obj) == list:\n",
        "            return r\"<sep/>\".join(\n",
        "                [self.json2token(item, update_special_tokens_for_json_key, sort_json_key) for item in obj]\n",
        "            )\n",
        "        else:\n",
        "            obj = str(obj)\n",
        "            if f\"<{obj}/>\" in added_tokens:\n",
        "                obj = f\"<{obj}/>\"  # for categorical special tokens\n",
        "            return obj\n",
        "    \n",
        "    def add_tokens(self, list_of_tokens: List[str]):\n",
        "        \"\"\"\n",
        "        Add special tokens to tokenizer and resize the token embeddings of the decoder\n",
        "        \"\"\"\n",
        "        newly_added_num = processor.tokenizer.add_tokens(list_of_tokens)\n",
        "        if newly_added_num > 0:\n",
        "            model.decoder.resize_token_embeddings(len(processor.tokenizer))\n",
        "            added_tokens.extend(list_of_tokens)\n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        return self.dataset_length - 1\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Load image from image_path of given dataset_path and convert into input_tensor and labels\n",
        "        Convert gt data into input_ids (tokenized string)\n",
        "        Returns:\n",
        "            input_tensor : preprocessed image\n",
        "            input_ids : tokenized gt_data\n",
        "            labels : masked labels (model doesn't need to predict prompt and pad token)\n",
        "        \"\"\"\n",
        "        sample = self.dataset[idx]\n",
        "\n",
        "        # input_tensor\n",
        "        pixel_values = processor(sample[\"image\"].convert(\"RGB\"), random_padding=self.split == \"train\", return_tensors=\"pt\").pixel_values\n",
        "        input_tensor = pixel_values.squeeze()\n",
        "\n",
        "        # input_ids\n",
        "        processed_parse = self.gt_token_sequences[idx]\n",
        "        input_ids = processor.tokenizer(\n",
        "            processed_parse,\n",
        "            add_special_tokens=False,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )[\"input_ids\"].squeeze(0)\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "          print(f\"sameple #{idx}, input_ids: {input_ids}\")\n",
        "\n",
        "        if self.split == \"train\":\n",
        "            labels = input_ids.clone()\n",
        "            labels[\n",
        "                labels == processor.tokenizer.pad_token_id\n",
        "            ] = self.ignore_id  # model doesn't need to predict pad token\n",
        "            labels[\n",
        "                : torch.nonzero(labels == self.prompt_end_token_id).sum() + 1\n",
        "            ] = self.ignore_id  # model doesn't need to predict prompt (for VQA)\n",
        "            return input_tensor, input_ids, labels\n",
        "        else:\n",
        "            prompt_end_index = torch.nonzero(\n",
        "                input_ids == self.prompt_end_token_id\n",
        "            ).sum()  # return prompt end index instead of target output labels\n",
        "            return input_tensor, input_ids, prompt_end_index, processed_parse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_h6nyTm3RN0",
        "outputId": "fe0dc9f4-97f2-403f-d434-d4f391016787"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['image', 'image_id', 'image_file_path', 'prompt', 'target_bounding_box'],\n",
              "        num_rows: 15624\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['image', 'image_id', 'image_file_path', 'prompt', 'target_bounding_box'],\n",
              "        num_rows: 471\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['image', 'image_id', 'image_file_path', 'prompt', 'target_bounding_box'],\n",
              "        num_rows: 565\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JpazNkf8CnA"
      },
      "outputs": [],
      "source": [
        "# we update some settings which differ from pretraining; namely the size of the images + no rotation required\n",
        "# source: https://github.com/clovaai/donut/blob/master/config/train_cord.yaml\n",
        "processor.feature_extractor.size = image_size[::-1] # should be (width, height)\n",
        "processor.feature_extractor.do_align_long_axis = False\n",
        "\n",
        "# pick only a small subset for initial training to see if the model converges on data\n",
        "max_train_samples = 1000\n",
        "range_train_samples = range(4000, 4000+max_train_samples)\n",
        "\n",
        "train_dataset = DonutDataset(REFEXP_DATASET_NAME, max_length=max_length, range_samples=range_train_samples,\n",
        "                             split=\"train\", task_start_token=\"<s_refexp>\", prompt_end_token=\"<s_target_bounding_box>\",\n",
        "                             sort_json_key=False,\n",
        "                             )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]\n"
      ],
      "metadata": {
        "id": "vlrKXSzLBAwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# pick only a small subset for initial training to see if model converges on data\n",
        "max_val_samples = 200\n",
        "range_val_samples = range(max_val_samples)\n",
        "\n",
        "val_dataset = DonutDataset(REFEXP_DATASET_NAME, max_length=max_length, range_samples=range_val_samples,\n",
        "                             split=\"validation\", task_start_token=\"<s_refexp>\", prompt_end_token=\"<s_target_bounding_box>\",\n",
        "                             sort_json_key=False,\n",
        "                             )\n"
      ],
      "metadata": {
        "id": "cxv4RS8i-rsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_values, decoder_input_ids, labels = train_dataset[0]\n"
      ],
      "metadata": {
        "id": "9ZUvmOdAs7xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_values.shape"
      ],
      "metadata": {
        "id": "AQMuNYnA4XYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "id": "vWKlLJML4o-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for decoder_input_id, label in zip(decoder_input_ids.tolist()[:-1], labels.tolist()[1:]):\n",
        "  if label != -100:\n",
        "    print(processor.decode([decoder_input_id]), processor.decode([label]))\n",
        "  else:\n",
        "    print(processor.decode([decoder_input_id]), label)"
      ],
      "metadata": {
        "id": "Zud4yPeN4qQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_values, decoder_input_ids, prompt_end_index, processed_parse = val_dataset[0]\n"
      ],
      "metadata": {
        "id": "0xcQqFDsBmPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_values.shape"
      ],
      "metadata": {
        "id": "Szz2rquaBq89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_end_index"
      ],
      "metadata": {
        "id": "1mUwVF9yBr_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_parse"
      ],
      "metadata": {
        "id": "cj2gybmeBuvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygTIylugfasG"
      },
      "source": [
        "## Create PyTorch DataLoaders\n",
        "\n",
        "Next, we create corresponding PyTorch DataLoaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLQ_Vl5MLugu"
      },
      "outputs": [],
      "source": [
        "print(f\"train dataset length: {train_dataset.dataset_length}\")\n",
        "print(f\"validation dataset length: {val_dataset.dataset_length}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=2)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "pIkar2gaX4Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxtTVgNnfdkD"
      },
      "source": [
        "Let's verify a batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHurHlLnL8Xm"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "pixel_values, decoder_input_ids, labels = batch\n",
        "print(pixel_values.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input_ids.shape"
      ],
      "metadata": {
        "id": "Vo0TXXDL8oHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that we have set the labels of all prompt tokens (which includes the prompt) to -100, to make sure the model doesn't learn to generate them. We only start to have labels starting from the \\<s_target_bounding_box> decoder input token."
      ],
      "metadata": {
        "id": "a_GvAiCQkPSf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8ehAwgPZrcc"
      },
      "outputs": [],
      "source": [
        "for decoder_input_id, label in zip(decoder_input_ids[0].tolist()[:-1][:50], labels[0].tolist()[1:][:50]):\n",
        "  if label != -100:\n",
        "    print(processor.decode([decoder_input_id]), processor.decode([label]))\n",
        "  else:\n",
        "    print(processor.decode([decoder_input_id]), label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnmD7rRy2WLI"
      },
      "source": [
        "## Define LightningModule\n",
        "\n",
        "We'll fine-tune the model using [PyTorch Lightning](https://www.pytorchlightning.ai/) here, but note that you can of course also just fine-tune with regular PyTorch, HuggingFace [Accelerate](https://github.com/huggingface/accelerate), the HuggingFace [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer), etc.\n",
        "\n",
        "PyTorch Lightning is pretty convenient to handle things like device placement, mixed precision and logging for you."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title We will use IoU to measure bounding box match as a validation progress metric instead of the Edit Distance metric used in DocVQA.\n",
        "\n",
        "def get_iou(bb1, bb2):\n",
        "    \"\"\"\n",
        "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
        "    Modifed version from the following original on stackoverflow:\n",
        "    https://stackoverflow.com/questions/25349178/calculating-percentage-of-bounding-box-overlap-for-image-detector-evaluation\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    bb1 : dict\n",
        "        Keys: {'xmin', 'xmax', 'ymin', 'ymax'}\n",
        "        The (xmin, ymin) position is at the top left corner,\n",
        "        the (xmax, y2) position is at the bottom right corner\n",
        "    bb2 : dict\n",
        "        Keys: {'xmin', 'xmax', 'ymin', 'ymax'}\n",
        "        The (x, y) position is at the top left corner,\n",
        "        the (xmax, ymax) position is at the bottom right corner\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        in [0, 1]\n",
        "    \"\"\"\n",
        "\n",
        "    # print(f\"IoU input bb1, bb2: {bb1} , {bb2}\")\n",
        "    # if predictions are not resulting in properly shaped bounding boxes, return no-match\n",
        "    if bb1['xmin'] >= bb1['xmax']:\n",
        "      return 0\n",
        "    if bb1['ymin'] >= bb1['ymax']:\n",
        "      return 0\n",
        "\n",
        "    # if any of the bounding box labels are not properly shaped, return no-match\n",
        "    if bb2['xmin'] >= bb2['xmax']:\n",
        "      return 0\n",
        "    if bb2['ymin'] >= bb2['ymax']:\n",
        "      return 0\n",
        "\n",
        "    # determine the coordinates of the intersection rectangle\n",
        "    x_left = max(bb1['xmin'], bb2['xmin'])\n",
        "    y_top = max(bb1['ymin'], bb2['ymin'])\n",
        "    x_right = min(bb1['xmax'], bb2['xmax'])\n",
        "    y_bottom = min(bb1['ymax'], bb2['ymax'])\n",
        "\n",
        "    # print(f\"IoU x_left: {x_left}, y_top: {y_top}, x_right: {x_right}, y_bottom: {y_bottom}\")\n",
        "\n",
        "    if x_right < x_left or y_bottom < y_top:\n",
        "        return 0.0\n",
        "\n",
        "    # The intersection of two axis-aligned bounding boxes is always an\n",
        "    # axis-aligned bounding box\n",
        "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "    # print(f\"IoU intersection_area: {intersection_area}\")\n",
        "\n",
        "    # compute the area of both AABBs\n",
        "    bb1_area = (bb1['xmax'] - bb1['xmin']) * (bb1['ymax'] - bb1['ymin'])\n",
        "    bb2_area = (bb2['xmax'] - bb2['xmin']) * (bb2['ymax'] - bb2['ymin'])\n",
        "    # print(f\"IoU bb1_area: {bb1_area}\")\n",
        "    # print(f\"IoU bb2_area: {bb2_area}\")\n",
        "\n",
        "    # compute the intersection over union by taking the intersection\n",
        "    # area and dividing it by the sum of prediction + ground-truth\n",
        "    # areas - the interesection area\n",
        "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
        "    # if iou > 0:\n",
        "    #   print(f\"IoU input bb1, bb2: {bb1} , {bb2}\")\n",
        "    #   print(f\"IoU : {iou}\")\n",
        "    assert iou >= 0.0\n",
        "    assert iou <= 1.0\n",
        "    return iou"
      ],
      "metadata": {
        "id": "AmDmvkkfnDef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRm5i4gWG-sb"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "# we will use IoU for RefExp instead of edit_distance\n",
        "# from nltk import edit_distance\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.utilities import rank_zero_only\n",
        "\n",
        "\n",
        "class DonutModelPLModule(pl.LightningModule):\n",
        "    def __init__(self, config, processor, model):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.processor = processor\n",
        "        self.model = model\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        pixel_values, decoder_input_ids, labels = batch\n",
        "        \n",
        "        outputs = self.model(pixel_values,\n",
        "                             decoder_input_ids=decoder_input_ids[:, :-1],\n",
        "                             labels=labels[:, 1:])\n",
        "        loss = outputs.loss\n",
        "        self.log_dict({\"train_loss\": loss}, sync_dist=True)\n",
        "        return loss\n",
        "\n",
        "    def token2bbox(self, seq: str):\n",
        "        target_bbox = self.processor.token2json(seq)\n",
        "        bbox = target_bbox.get('target_bounding_box')\n",
        "        if bbox is None:\n",
        "          print(f\"token2bbox seq has no target_bounding_box, seq:{seq}\")\n",
        "          bbox = bbox = {\"xmin\": 0, \"ymin\": 0, \"xmax\": 0, \"ymax\": 0}\n",
        "          return bbox\n",
        "        # print(f\"token2 bounding box json: {bbox}\")\n",
        "        # safeguard in case text prediction is missing some bounding box coordinates\n",
        "        # or coordinates are not valid numeric values\n",
        "        try:\n",
        "          xmin = float(bbox.get(\"xmin\", 0))\n",
        "        except ValueError:\n",
        "          xmin = 0\n",
        "        try:\n",
        "          ymin = float(bbox.get(\"ymin\", 0))\n",
        "        except ValueError:\n",
        "          ymin = 0\n",
        "        try:\n",
        "          xmax = float(bbox.get(\"xmax\", 1))\n",
        "        except ValueError:\n",
        "          xmax = 1\n",
        "        try:\n",
        "          ymax = float(bbox.get(\"ymax\", 1))\n",
        "        except ValueError:\n",
        "          ymax = 1\n",
        "        # replace str with float coords\n",
        "        bbox = {\"xmin\": xmin, \"ymin\": ymin, \"xmax\": xmax, \"ymax\": ymax}\n",
        "        # print(f\"token2 bounding box float: {bbox}\")\n",
        "        return bbox\n",
        "\n",
        "    def validation_step(self, batch, batch_idx, dataset_idx=0):\n",
        "        pixel_values, decoder_input_ids, prompt_end_idxs, answers = batch\n",
        "        decoder_prompts = pad_sequence(\n",
        "            [input_id[: end_idx + 1] for input_id, end_idx in zip(decoder_input_ids, prompt_end_idxs)],\n",
        "            batch_first=True,\n",
        "        )\n",
        "        \n",
        "        outputs = self.model.generate(pixel_values,\n",
        "                                   decoder_input_ids=decoder_prompts,\n",
        "                                   max_length=max_length,\n",
        "                                   early_stopping=True,\n",
        "                                   pad_token_id=self.processor.tokenizer.pad_token_id,\n",
        "                                   eos_token_id=self.processor.tokenizer.eos_token_id,\n",
        "                                   use_cache=True,\n",
        "                                   num_beams=1,\n",
        "                                   bad_words_ids=[[self.processor.tokenizer.unk_token_id]],\n",
        "                                   return_dict_in_generate=True,)\n",
        "    \n",
        "        predictions = []\n",
        "        for seq in self.processor.tokenizer.batch_decode(outputs.sequences):\n",
        "            seq = seq.replace(self.processor.tokenizer.eos_token, \"\").replace(self.processor.tokenizer.pad_token, \"\")\n",
        "            seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()  # remove first task start token\n",
        "            predictions.append(seq)\n",
        "\n",
        "        scores = list()\n",
        "        for pred, answer in zip(predictions, answers):\n",
        "            answer = re.sub(r\"<.*?>\", \"\", answer, count=1)\n",
        "            answer = answer.replace(self.processor.tokenizer.eos_token, \"\")\n",
        "            answer_bbox = self.token2bbox(answer)\n",
        "            pred_bbox = self.token2bbox(pred)\n",
        "            scores.append(get_iou(pred_bbox, answer_bbox))\n",
        "            if self.config.get(\"verbose\", False) and len(scores) == 1:\n",
        "              print(f\"      Prediction: {pred}\")\n",
        "              print(f\"          Answer: {answer}\")\n",
        "              print(f\" Prediction bbox: {pred_bbox}\")\n",
        "              print(f\"     Answer bbox: {answer_bbox}\")\n",
        "              print(f\"IoU (bbox match): {scores[0]}\")\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def validation_epoch_end(self, validation_step_outputs):\n",
        "        # I set this to 1 manually\n",
        "        # (previously set to len(self.config.dataset_name_or_paths))\n",
        "        num_of_loaders = 1\n",
        "        if num_of_loaders == 1:\n",
        "            validation_step_outputs = [validation_step_outputs]\n",
        "        assert len(validation_step_outputs) == num_of_loaders\n",
        "        cnt = [0] * num_of_loaders\n",
        "        total_metric = [0] * num_of_loaders\n",
        "        val_metric = [0] * num_of_loaders\n",
        "        for i, results in enumerate(validation_step_outputs):\n",
        "            for scores in results:\n",
        "                cnt[i] += len(scores)\n",
        "                total_metric[i] += np.sum(scores)\n",
        "            val_metric[i] = total_metric[i] / cnt[i]\n",
        "            val_metric_name = f\"val_metric_{i}th_dataset\"\n",
        "            self.log_dict({val_metric_name: val_metric[i]}, sync_dist=True)\n",
        "        self.log_dict({\"val_metric\": np.sum(total_metric) / np.sum(cnt)}, sync_dist=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # TODO add scheduler\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.config.get(\"lr\"))\n",
        "    \n",
        "        return optimizer\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return train_dataloader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return val_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we instantiate the module:"
      ],
      "metadata": {
        "id": "bKujfvIDlAHo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxNJhCGjKhtR"
      },
      "outputs": [],
      "source": [
        "config = {\"max_epochs\": 5, # 30,\n",
        "          \"val_check_interval\":0.2, # how many times we want to validate during an epoch\n",
        "          \"check_val_every_n_epoch\":1,\n",
        "          \"gradient_clip_val\":1.0,\n",
        "          \"num_training_samples_per_epoch\": 800,\n",
        "          \"lr\":3e-5,\n",
        "          \"train_batch_sizes\": [8],\n",
        "          \"val_batch_sizes\": [1],\n",
        "          # \"seed\":2022,\n",
        "          \"num_nodes\": 1,\n",
        "          \"warmup_steps\": 300, # 800/8*30/10, 10%\n",
        "          \"result_path\": \"./result\",\n",
        "          \"verbose\": True,\n",
        "          }\n",
        " \n",
        "model_module = DonutModelPLModule(config, processor, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZoPiDOPKg0o"
      },
      "source": [
        "## Train!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "# clear any previously open logging session\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "GQhXL0AdWpuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiK6-vQHKnBy"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.loggers import WandbLogger\n",
        " \n",
        "\n",
        "wandb_logger = WandbLogger(project=\"Donut-RefExp\")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "        accelerator=\"gpu\",\n",
        "        devices=1,\n",
        "        max_epochs=config.get(\"max_epochs\"),\n",
        "        val_check_interval=config.get(\"val_check_interval\"),\n",
        "        check_val_every_n_epoch=config.get(\"check_val_every_n_epoch\"),\n",
        "        gradient_clip_val=config.get(\"gradient_clip_val\"),\n",
        "        precision=16, # we'll use mixed precision\n",
        "        num_sanity_val_steps=0,\n",
        "        logger=wandb_logger,\n",
        "        # callbacks=[lr_callback, checkpoint_callback],\n",
        ")\n",
        "\n",
        "trainer.fit(model_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push to hub and reuse\n",
        "\n",
        "HuggingFace's [hub](https://huggingface.co/) is a nice place to host, version and share machine learning models (and datasets, and demos in the form of [Spaces](https://huggingface.co/spaces)).\n",
        "\n",
        "We first provide our authentication token."
      ],
      "metadata": {
        "id": "1xl4AeMl3jmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pushing to the hub after training is as easy as:"
      ],
      "metadata": {
        "id": "7X7GV-YE5loA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo_name = \"ivelin/donut-refexp-draft\"\n",
        "\n",
        "#\n",
        "# here we push the processor and model to the hub\n",
        "# note that you can add `private=True` in case you're using the private hub\n",
        "# which makes sure the model is only shared with your colleagues\n",
        "model_module.processor.push_to_hub(repo_name) \n",
        "model_module.model.push_to_hub(repo_name)\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "gY24Xk8IDtNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reloading can then be done as:"
      ],
      "metadata": {
        "id": "lN_F7nY67cre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "\n",
        "processor = DonutProcessor.from_pretrained(repo_name)\n",
        "model = VisionEncoderDecoderModel.from_pretrained(repo_name)\n",
        "\n",
        "backup_repo_name = \"ivelin/donut-refexp-draft-backup\"\n",
        "\n",
        "# save a backup in case uploading to the main model fails and corrupts the data\n",
        "model_module.processor.push_to_hub(backup_repo_name) \n",
        "model_module.model.push_to_hub(backup_repo_name)\n"
      ],
      "metadata": {
        "id": "chaFQM0R3mrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "\n",
        "For inference, we refer to the [docs](https://huggingface.co/docs/transformers/main/en/model_doc/donut#inference) of Donut, or the [UI RefExp playspace](https://huggingface.co/spaces/ivelin/ui-refexp)."
      ],
      "metadata": {
        "id": "9t50qDh-lGMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Dph3FRU6p67k"
      }
    }
  ]
}